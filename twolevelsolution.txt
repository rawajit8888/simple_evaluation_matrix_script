def fit(self, event, data, tasks, **kwargs):
        """
        3-Level Hierarchical Training Pipeline
        
        Level 1: Email â†’ MasterDepartment
        Level 2: Email + MasterDepartment â†’ Department
        Level 3: Email + MasterDepartment + Department â†’ QueryType
        """
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ 3-LEVEL HIERARCHICAL TRAINING INITIATED")
        self.logger.info("=" * 80)
        
        # Initialize database
        self.init_metrics_db()
        
        # ========== PREPARE DATA ==========
        self.logger.info("ğŸ“Š Preparing training data...")
        
        train_data = []
        for task in tasks:
            extracted = self._extract_taxonomy_from_task(task)
            if extracted and extracted['text']:
                train_data.append(extracted)
        
        if len(train_data) == 0:
            self.logger.error("âŒ No valid training data found")
            self.logger.error("Please check your Label Studio annotations:")
            self.logger.error("  - Ensure tasks have 'masterdepartment' labels")
            self.logger.error("  - Check that taxonomy fields are properly configured")
            return
        
        self.logger.info(f"âœ“ Prepared {len(train_data)} training samples")
        
        # Log sample for debugging
        if train_data:
            sample = train_data[0]
            self.logger.info(f"ğŸ“ Sample annotation:")
            self.logger.info(f"   MasterDepartment: {sample['masterdepartment']}")
            self.logger.info(f"   Department: {sample['department']}")
            self.logger.info(f"   QueryType: {sample['querytype']}")
        
        # Log distribution
        masterdept_count = sum(1 for d in train_data if d['masterdepartment'])
        dept_count = sum(1 for d in train_data if d['department'])
        qt_count = sum(1 for d in train_data if d['querytype'])
        
        self.logger.info(f"ğŸ“Š Label distribution:")
        self.logger.info(f"   Level 1 (MasterDepartment): {masterdept_count} samples")
        self.logger.info(f"   Level 2 (Department): {dept_count} samples")
        self.logger.info(f"   Level 3 (QueryType): {qt_count} samples")
        
        # Convert to DataFrame
        df = pd.DataFrame(train_data)
        
        from sklearn.model_selection import train_test_split
        
        # ========== TRAIN LEVEL 1: MasterDepartment ONLY ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ğŸ¯ LEVEL 1 TRAINING: MasterDepartment ONLY")
        self.logger.info("=" * 80)
        
        # Split for Level 1
        class_counts = df['masterdepartment'].value_counts()
        min_samples = class_counts.min()
        
        if min_samples >= 2:
            self.logger.info(f"âœ“ Using stratified split (min class size: {min_samples})")
            try:
                level1_train_df, level1_test_df = train_test_split(
                    df, test_size=0.2, random_state=42, 
                    stratify=df['masterdepartment']
                )
            except ValueError as e:
                self.logger.warning(f"âš ï¸  Stratified split failed: {e}")
                self.logger.warning("âš ï¸  Falling back to random split")
                level1_train_df, level1_test_df = train_test_split(
                    df, test_size=0.2, random_state=42
                )
        else:
            self.logger.warning(f"âš ï¸  Some classes have only 1 sample - using random split")
            level1_train_df, level1_test_df = train_test_split(
                df, test_size=0.2, random_state=42
            )
        
        self.logger.info(f"ğŸ“Š Level 1 - Train: {len(level1_train_df)} | Test: {len(level1_test_df)}")
        self._train_level1(level1_train_df, level1_test_df)
        
        # ========== TRAIN LEVEL 2: Department ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ğŸ¯ LEVEL 2 TRAINING: Department")
        self.logger.info("=" * 80)
        
        # Filter samples with department labels FIRST
        dept_df = df[df['department'].notna()].copy()
        
        if len(dept_df) > 0:
            self.logger.info(f"ğŸ“Š Department samples: {len(dept_df)}")
            
            # NOW split the filtered data
            dept_class_counts = dept_df['department'].value_counts()
            dept_min_samples = dept_class_counts.min()
            
            if dept_min_samples >= 2:
                self.logger.info(f"âœ“ Using stratified split for departments (min class size: {dept_min_samples})")
                try:
                    dept_train_df, dept_test_df = train_test_split(
                        dept_df, test_size=0.2, random_state=42,
                        stratify=dept_df['department']
                    )
                except ValueError as e:
                    self.logger.warning(f"âš ï¸  Stratified split failed: {e}")
                    self.logger.warning("âš ï¸  Falling back to random split")
                    dept_train_df, dept_test_df = train_test_split(
                        dept_df, test_size=0.2, random_state=42
                    )
            else:
                self.logger.warning(f"âš ï¸  Some department classes have only 1 sample - using random split")
                dept_train_df, dept_test_df = train_test_split(
                    dept_df, test_size=0.2, random_state=42
                )
            
            self.logger.info(f"ğŸ“Š Level 2 - Train: {len(dept_train_df)} | Test: {len(dept_test_df)}")
            self._train_level2(dept_train_df, dept_test_df)
        else:
            self.logger.warning("âš ï¸  No Department labels found - skipping Level 2 training")
        
        # ========== TRAIN LEVEL 3: QueryType ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ğŸ¯ LEVEL 3 TRAINING: QueryType")
        self.logger.info("=" * 80)
        
        # Filter samples with querytype labels FIRST
        qt_df = df[df['querytype'].notna()].copy()
        
        if len(qt_df) > 0:
            self.logger.info(f"ğŸ“Š QueryType samples: {len(qt_df)}")
            
            # NOW split the filtered data
            qt_class_counts = qt_df['querytype'].value_counts()
            qt_min_samples = qt_class_counts.min()
            
            if qt_min_samples >= 2:
                self.logger.info(f"âœ“ Using stratified split for querytypes (min class size: {qt_min_samples})")
                try:
                    qt_train_df, qt_test_df = train_test_split(
                        qt_df, test_size=0.2, random_state=42,
                        stratify=qt_df['querytype']
                    )
                except ValueError as e:
                    self.logger.warning(f"âš ï¸  Stratified split failed: {e}")
                    self.logger.warning("âš ï¸  Falling back to random split")
                    qt_train_df, qt_test_df = train_test_split(
                        qt_df, test_size=0.2, random_state=42
                    )
            else:
                self.logger.warning(f"âš ï¸  Some querytype classes have only 1 sample - using random split")
                qt_train_df, qt_test_df = train_test_split(
                    qt_df, test_size=0.2, random_state=42
                )
            
            self.logger.info(f"ğŸ“Š Level 3 - Train: {len(qt_train_df)} | Test: {len(qt_test_df)}")
            self._train_level3(qt_train_df, qt_test_df)
        else:
            self.logger.warning("âš ï¸  No QueryType labels found - skipping Level 3 training")
        
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ğŸ‰ 3-LEVEL HIERARCHICAL TRAINING COMPLETE")
        self.logger.info("=" * 80)







#evaluatin matrix save to folder 

def save_evaluation_to_files(self, level, level_name, test_df, true_labels, pred_labels, accuracy, f1):
        """
        Save evaluation results to files:
        - CSV with test predictions
        - Text file with classification report
        - Text file with confusion matrix
        """
        from sklearn.metrics import classification_report, confusion_matrix
        
        # Create evaluation folder
        eval_dir = os.path.join(self.model_dir, "evaluation", level_name)
        os.makedirs(eval_dir, exist_ok=True)
        
        self.logger.info(f"ğŸ“ Creating evaluation folder: {eval_dir}")
        
        # ========== SAVE TEST PREDICTIONS TO CSV ==========
        predictions_df = test_df.copy()
        predictions_df['true_label'] = true_labels
        predictions_df['predicted_label'] = pred_labels
        predictions_df['correct'] = predictions_df['true_label'] == predictions_df['predicted_label']
        
        csv_path = os.path.join(eval_dir, f"{level_name}_test_predictions.csv")
        predictions_df.to_csv(csv_path, index=False)
        self.logger.info(f"ğŸ’¾ Test predictions saved to: {csv_path}")
        
        # ========== SAVE CLASSIFICATION REPORT ==========
        report = classification_report(true_labels, pred_labels, zero_division=0)
        report_path = os.path.join(eval_dir, f"{level_name}_classification_report.txt")
        
        with open(report_path, 'w') as f:
            f.write(f"=" * 80 + "\n")
            f.write(f"CLASSIFICATION REPORT - {level_name.upper()}\n")
            f.write(f"=" * 80 + "\n")
            f.write(f"Overall Accuracy: {accuracy:.4f}\n")
            f.write(f"Overall F1-Score: {f1:.4f}\n")
            f.write(f"=" * 80 + "\n\n")
            f.write(report)
        
        self.logger.info(f"ğŸ’¾ Classification report saved to: {report_path}")
        
        # ========== SAVE CONFUSION MATRIX ==========
        cm = confusion_matrix(true_labels, pred_labels)
        cm_path = os.path.join(eval_dir, f"{level_name}_confusion_matrix.txt")
        
        with open(cm_path, 'w') as f:
            f.write(f"=" * 80 + "\n")
            f.write(f"CONFUSION MATRIX - {level_name.upper()}\n")
            f.write(f"=" * 80 + "\n\n")
            f.write(str(cm))
            f.write("\n")
        
        self.logger.info(f"ğŸ’¾ Confusion matrix saved to: {cm_path}")
        
        # ========== SAVE SUMMARY ==========
        summary_path = os.path.join(eval_dir, f"{level_name}_summary.txt")
        
        with open(summary_path, 'w') as f:
            f.write(f"=" * 80 + "\n")
            f.write(f"EVALUATION SUMMARY - {level_name.upper()}\n")
            f.write(f"=" * 80 + "\n")
            f.write(f"Level: {level}\n")
            f.write(f"Training samples: {len(test_df)}\n")
            f.write(f"Accuracy: {accuracy:.4f}\n")
            f.write(f"F1-Score: {f1:.4f}\n")
            f.write(f"Number of classes: {len(set(true_labels))}\n")
            f.write(f"Correct predictions: {sum(predictions_df['correct'])}\n")
            f.write(f"Incorrect predictions: {sum(~predictions_df['correct'])}\n")
            f.write(f"=" * 80 + "\n")
        
        self.logger.info(f"ğŸ’¾ Summary saved to: {summary_path}")
        self.logger.info(f"âœ… Evaluation files created in: {eval_dir}")





# Save evaluation to files
        self.save_evaluation_to_files(
            level=1,
            level_name="masterdepartment",
            test_df=test_df,
            true_labels=decoded_masterdept_true,
            pred_labels=decoded_masterdept_pred,
            accuracy=masterdept_accuracy,
            f1=masterdept_f1
        )










# Save evaluation to files
        self.save_evaluation_to_files(
            level=2,
            level_name="department",
            test_df=test_df,
            true_labels=decoded_dept_true,
            pred_labels=decoded_dept_pred,
            accuracy=dept_accuracy,
            f1=dept_f1
        )











# Save evaluation to files
        self.save_evaluation_to_files(
            level=3,
            level_name="querytype",
            test_df=test_df,
            true_labels=decoded_qt_true,
            pred_labels=decoded_qt_pred,
            accuracy=qt_accuracy,
            f1=qt_f1
        )
```

---

## **Summary of Changes:**

**1. Line ~768**: Add the new `save_evaluation_to_files()` method (65 lines)

**2. Line 1352**: Add evaluation file saving call for Level 1

**3. Line 1489**: Add evaluation file saving call for Level 2

**4. Line 1626**: Add evaluation file saving call for Level 3

---

## **What This Creates:**

After training, you'll get this folder structure:
```
./results/bert-classification-sentiment3level_training/
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ masterdepartment/
â”‚   â”‚   â”œâ”€â”€ masterdepartment_test_predictions.csv
â”‚   â”‚   â”œâ”€â”€ masterdepartment_classification_report.txt
â”‚   â”‚   â”œâ”€â”€ masterdepartment_confusion_matrix.txt
â”‚   â”‚   â””â”€â”€ masterdepartment_summary.txt
â”‚   â”œâ”€â”€ department/
â”‚   â”‚   â”œâ”€â”€ department_test_predictions.csv
â”‚   â”‚   â”œâ”€â”€ department_classification_report.txt
â”‚   â”‚   â”œâ”€â”€ department_confusion_matrix.txt
â”‚   â”‚   â””â”€â”€ department_summary.txt
â”‚   â””â”€â”€ querytype/
â”‚       â”œâ”€â”€ querytype_test_predictions.csv
â”‚       â”œâ”€â”€ querytype_classification_report.txt
â”‚       â”œâ”€â”€ querytype_confusion_matrix.txt
â”‚       â””â”€â”€ querytype_summary.txt
â”œâ”€â”€ metrics.db  (SQLite database - still created)
â”œâ”€â”€ masterdepartment_model/
â”œâ”€â”€ department_model/
â””â”€â”€ querytype_model/