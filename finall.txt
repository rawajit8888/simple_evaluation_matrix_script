import pickle
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
from datasets import Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments

# ================================
# 1. LOAD LABEL ENCODER
# ================================
print("Loading label encoder...")
with open("label_encoder.pkl", "rb") as f:
    label_encoder = pickle.load(f)

num_labels = len(label_encoder.classes_)
print(f"Total labels in encoder: {num_labels}")

# ================================
# 2. LOAD TRAINED MODEL
# ================================
model_path = "models/finetuned_model"
print(f"Loading model from: {model_path}")

model = AutoModelForSequenceClassification.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

print(f"Model loaded! num_labels = {model.num_labels}")

# ================================
# 3. LOAD FULL CSV (ALL 6500 ROWS)
# ================================
csv_path = "data/project-3-at.csv"
print(f"Loading evaluation CSV: {csv_path}")

df = pd.read_csv(csv_path)
df = df[["html", "classification"]]

print(f"Dataset size: {len(df)} rows")
print(f"Unique categories in CSV: {df['classification'].nunique()}")

# ================================
# 4. Encode TRUE LABELS
# ================================
df["label"] = label_encoder.transform(df["classification"])

# Convert to HF Dataset
dataset = Dataset.from_pandas(df)

# ================================
# 5. Tokenizer Function
# ================================
def tokenize(batch):
    return tokenizer(
        batch["html"],
        padding="max_length",
        truncation=True,
        max_length=256,
    )

dataset = dataset.map(tokenize, batched=True)
dataset = dataset.remove_columns(["html", "classification"])
dataset = dataset.rename_column("label", "labels")
dataset.set_format("torch")

# ================================
# 6. Run Prediction
# ================================
print("Running predictions on all samples...")

training_args = TrainingArguments(output_dir="eval_tmp", per_device_eval_batch_size=16)
trainer = Trainer(model=model, args=training_args)

pred_output = trainer.predict(dataset)

y_true = pred_output.label_ids
y_pred = np.argmax(pred_output.predictions, axis=-1)

# ================================
# 7. Print Classification Report
# ================================
print("\n=============================================================")
print("           FINAL EVALUATION REPORT (ALL 302 LABELS)")
print("=============================================================\n")

report = classification_report(
    y_true,
    y_pred,
    target_names=label_encoder.classes_,
    zero_division=0
)

print(report)
