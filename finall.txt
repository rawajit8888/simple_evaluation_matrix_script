import os
import pandas as pd
import torch
import pickle
from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# ---------------------------------------------------------
# >>>>>>>>>>>>>>>> CHANGE THESE 3 PATHS <<<<<<<<<<<<<<<<<<
# ---------------------------------------------------------
MODEL_DIR = r"E:\Featsystems\evaluation_matrix\finetuned_multitask_model"
ENCODER_PATH = r"E:\Featsystems\evaluation_matrix\finetuned_multitask_model\encoders\classification.labels.pkl"
CSV_PATH = r"E:\Featsystems\evaluation_matrix\project-3-at.csv"
TEXT_COLUMN = "html"
LABEL_COLUMN = "classification"
# ---------------------------------------------------------

print("\n========== LOADING CSV ==========")
df = pd.read_csv(CSV_PATH)
df = df[[TEXT_COLUMN, LABEL_COLUMN]].dropna()
print(f"Loaded rows: {len(df)}")
print("Sample labels:", df[LABEL_COLUMN].unique()[:10])

# ---------------------------------------------------------
# LOAD LABEL ENCODER
# ---------------------------------------------------------
print("\n========== LOADING LABEL ENCODER ==========")
with open(ENCODER_PATH, "rb") as f:
    encoder = pickle.load(f)

label2id = encoder["label2id"]
id2label = encoder["id2label"]

print(f"Encoder detected {len(label2id)} labels")
print("First 10 labels:", list(label2id.items())[:10])

num_labels = len(label2id)

# ---------------------------------------------------------
# LOAD TRAINED MODEL (WITH CORRECT CLASSIFICATION HEAD)
# ---------------------------------------------------------
print("\n========== LOADING TRAINED MODEL ==========")

config = AutoConfig.from_pretrained(MODEL_DIR)
config.num_labels = num_labels  # force correct number of labels
config.id2label = id2label
config.label2id = label2id

model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_DIR,
    config=config
)

tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)

print("Model loaded:")
print(f" - num_labels = {model.config.num_labels}")
print(f" - id2label example = {list(model.config.id2label.items())[:5]}")

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
model.eval()

# ---------------------------------------------------------
# RUN PREDICTIONS
# ---------------------------------------------------------
print("\n========== RUNNING PREDICTIONS ==========\n")

y_true_ids = []
y_pred_ids = []

for i, row in df.iterrows():
    text = str(row[TEXT_COLUMN])
    true_label = row[LABEL_COLUMN]

    # True label ID
    if true_label not in label2id:
        continue
    y_true_ids.append(label2id[true_label])

    # Tokenize
    inputs = tokenizer(
        text,
        max_length=256,
        padding="max_length",
        truncation=True,
        return_tensors="pt"
    ).to(device)

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        pred_id = torch.argmax(logits, dim=1).item()

    y_pred_ids.append(pred_id)

    # Debug first 3 rows
    if i < 3:
        print("--------------------------------------------------")
        print("TEXT:", text[:200], "...")
        print("TRUE LABEL:", true_label)
        print("PRED LABEL:", id2label[pred_id])
        print("LOGITS:", logits.cpu().numpy())

# ---------------------------------------------------------
# METRICS
# ---------------------------------------------------------
print("\n========== RESULTS ==========\n")

print("Accuracy:", accuracy_score(y_true_ids, y_pred_ids))

precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(
    y_true_ids, y_pred_ids, average="macro", zero_division=0
)

precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
    y_true_ids, y_pred_ids, average="weighted", zero_division=0
)

print(f"Precision (macro):   {precision_macro:.4f}")
print(f"Recall (macro):      {recall_macro:.4f}")
print(f"F1 Score (macro):    {f1_macro:.4f}\n")

print(f"Precision (weighted):{precision_weighted:.4f}")
print(f"Recall (weighted):   {recall_weighted:.4f}")
print(f"F1 Score (weighted): {f1_weighted:.4f}\n")

print("\n========== FULL CLASSIFICATION REPORT ==========\n")
print(classification_report(
    y_true_ids,
    y_pred_ids,
    target_names=[id2label[i] for i in range(num_labels)],
    zero_division=0
))
