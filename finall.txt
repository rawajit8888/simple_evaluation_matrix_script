import torch
import pandas as pd
import pickle
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.metrics import classification_report, accuracy_score
from tqdm import tqdm

# -------------------------
# CONFIG
# -------------------------
MODEL_DIR = r"E:/Featsystems/evaluatio/finetunedmultitaskmodel"
CSV_PATH = r"E:/Featsystems/evaluatio/project-3-at.csv"
TEXT_COL = "html"
LABEL_COL = "classification"

# -------------------------
# LOAD LABEL ENCODER
# -------------------------
ENCODER_PATH = MODEL_DIR + "/encoders/classification_labels.pkl"

with open(ENCODER_PATH, "rb") as f:
    label_encoder: dict = pickle.load(f)

label2id = label_encoder
id2label = {v: k for k, v in label2id.items()}

num_labels = len(label2id)
print("Total labels in encoder:", num_labels)

# -------------------------
# LOAD TOKENIZER
# (Multilingual BERT tokenizer)
# -------------------------
tokenizer = BertTokenizer.from_pretrained(
    MODEL_DIR,  # must read tokenizer.json + vocab.txt from fine-tuned folder
    local_files_only=True
)

# -------------------------
# LOAD FINE-TUNED MODEL
# (Restores correct num_labels)
# -------------------------
model = BertForSequenceClassification.from_pretrained(
    MODEL_DIR,       # Loads config.json + model.safetensors
    num_labels=num_labels,
    id2label=id2label,
    label2id=label2id,
    local_files_only=True
)
model.eval()

print("Model loaded successfully.")
print("Config num_labels =", model.config.num_labels)
print("Label preview:", list(model.config.id2label.items())[:5])

# -------------------------
# LOAD EVALUATION CSV
# -------------------------
df = pd.read_csv(CSV_PATH)

texts = df[TEXT_COL].astype(str).tolist()
true_labels = df[LABEL_COL].astype(str).tolist()

# TRUE → IDS
true_ids = [label2id[x] for x in true_labels]

pred_ids = []

# -------------------------
# INFERENCE
# -------------------------
for text in tqdm(texts, desc="Running inference"):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        pred_id = torch.argmax(logits, dim=1).item()

    pred_ids.append(pred_id)

# IDS → LABELS
pred_labels = [id2label[i] for i in pred_ids]

# -------------------------
# SAVE CSV
# -------------------------
df["y_pred"] = pred_labels
df.to_csv("evaluation_output.csv", index=False)

# -------------------------
# METRICS
# -------------------------
print("\n--------- FINAL METRICS ---------\n")
print("Accuracy:", accuracy_score(true_labels, pred_labels))
print(classification_report(true_labels, pred_labels))
