# -------------------------------
# Full Evaluation Script (Taxonomy Fix)
# -------------------------------

import pandas as pd
import torch
from torch.utils.data import DataLoader, TensorDataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pickle
from sklearn.metrics import classification_report
from torch.nn import functional as F
import json

# -------------------------------
# 1. CONFIGURE PATHS
# -------------------------------
CSV_FILE = "your_data.csv"
TEXT_COLUMN = "Subject"
LABEL_COLUMN = "classification"
MODEL_DIR = "path_to_trained_model"
ENCODER_FILE = "encoders/classification.labels.pkl"
BATCH_SIZE = 16

# -------------------------------
# 2. LOAD LABEL ENCODER
# -------------------------------
with open(ENCODER_FILE, "rb") as f:
    label_encoder = pickle.load(f)

num_labels = len(label_encoder.classes_)
print(f"Number of categories: {num_labels}")
print("Example classes:", label_encoder.classes_[:5])

# -------------------------------
# 3. FUNCTION TO FIX TAXONOMY LABEL
# -------------------------------
def fix_taxonomy(raw_label):
    """
    Converts taxonomy JSON string into a flattened label
    """
    try:
        # Convert string → dict
        data = json.loads(raw_label)
        
        # Extract taxonomy array
        taxonomy_list = data["taxonomy"][0]
        
        # Join with > (same style as encoder)
        return " > ".join(taxonomy_list)
    
    except Exception as e:
        print("Error parsing taxonomy:", raw_label, e)
        return None

# -------------------------------
# 4. LOAD CSV
# -------------------------------
df = pd.read_csv(CSV_FILE)

# Fix label format
df["fixed_label"] = df[LABEL_COLUMN].apply(fix_taxonomy)

# Drop any errors
df = df[df["fixed_label"].notnull()]

# Encode labels using encoder
df["label_id"] = df["fixed_label"].map(lambda x: label_encoder.transform([x])[0])

# -------------------------------
# 5. LOAD MODEL
# -------------------------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_DIR, num_labels=num_labels
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# -------------------------------
# 6. PREPARE DATASET
# -------------------------------
texts = df[TEXT_COLUMN].astype(str).tolist()
labels = df["label_id"].tolist()

encodings = tokenizer(texts, padding=True, truncation=True, return_tensors="pt", max_length=512)
dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels))

loader = DataLoader(dataset, batch_size=BATCH_SIZE)

# -------------------------------
# 7. RUN INFERENCE
# -------------------------------
all_preds = []

with torch.no_grad():
    for batch in loader:
        input_ids, attention_mask, _ = [x.to(device) for x in batch]
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        preds = torch.argmax(F.softmax(outputs.logits, dim=1), dim=1)
        all_preds.extend(preds.cpu().numpy())

# -------------------------------
# 8. MAP PREDICTIONS
# -------------------------------
df['y_pred'] = label_encoder.inverse_transform(all_preds)

# -------------------------------
# 9. METRICS
# -------------------------------
print("\nClassification Report:\n")
print(classification_report(df['fixed_label'], df['y_pred'], digits=4))

# -------------------------------
# 10. SAVE OUTPUT
# -------------------------------
df.to_csv("evaluation_results.csv", index=False)
print("\nSAVED → evaluation_results.csv")
