# ================================================
# Full Evaluation Script for Label Studio CSV
# Handles nested taxonomy automatically
# Generates predictions, metrics, and confusion matrix
# Safe: Offline, no backend interaction
# ================================================

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns
import json
import ast
import os

# --------------------------
# CONFIGURATION - UPDATE THIS
# --------------------------
MODEL_PATH = "C:/path_to_your_model"       # trained model folder
CSV_PATH = "C:/path_to_your_csv/emails.csv" # Label Studio exported CSV
TEXT_COL = "text"                           # column containing email/text
LABEL_COL = "classification"                # column containing taxonomy/label
SAVE_DIR = "C:/path_to_save_results"        # folder to save outputs

os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------
# FUNCTION TO EXTRACT READABLE LABEL
# --------------------------
def extract_label(cell_value):
    """
    Converts Label Studio classification column like:
    '[{"taxonomy":[["Internet Banking","Account Access","Unblock"]]}]'
    into readable label string:
    'Internet Banking > Account Access > Unblock'
    """
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except Exception as e:
        return "Unknown"

# --------------------------
# 1. LOAD MODEL
# --------------------------
print("Loading model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
print("Model loaded on", device)

# --------------------------
# 2. LOAD CSV
# --------------------------
print("Loading CSV...")
df = pd.read_csv(CSV_PATH)
if TEXT_COL not in df.columns or LABEL_COL not in df.columns:
    raise ValueError(f"CSV must contain columns '{TEXT_COL}' and '{LABEL_COL}'")

texts = df[TEXT_COL].tolist()
y_true = [extract_label(x) for x in df[LABEL_COL]]
print(f"Loaded {len(texts)} rows")

# --------------------------
# 3. GENERATE PREDICTIONS
# --------------------------
print("Generating predictions...")
y_pred = []
y_conf = []

for text in texts:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits
    pred_id = torch.argmax(logits, dim=-1).item()
    prob = torch.softmax(logits, dim=-1)[0][pred_id].item()
    y_pred.append(pred_id)
    y_conf.append(prob)

# Convert prediction ids to labels if model has mapping
if hasattr(model.config, "id2label"):
    y_pred_labels = [model.config.id2label[p] for p in y_pred]
else:
    y_pred_labels = y_pred

# --------------------------
# 4. EVALUATION METRICS
# --------------------------
print("Computing metrics...")
report = classification_report(y_true, y_pred_labels, output_dict=True)
accuracy = accuracy_score(y_true, y_pred_labels)
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_labels, average='weighted')

print("\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred_labels))
print(f"Accuracy: {accuracy:.4f}")
print(f"Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

# --------------------------
# 5. CONFUSION MATRIX
# --------------------------
labels_sorted = sorted(list(set(y_true)))
cm = confusion_matrix(y_true, y_pred_labels, labels=labels_sorted)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=labels_sorted, yticklabels=labels_sorted)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
cm_path = os.path.join(SAVE_DIR, "confusion_matrix.png")
plt.savefig(cm_path)
plt.close()
print(f"Confusion matrix saved to {cm_path}")

# --------------------------
# 6. SAVE RESULTS
# --------------------------
# JSON summary
results = {
    "accuracy": float(accuracy),
    "weighted_precision": float(precision),
    "weighted_recall": float(recall),
    "weighted_f1": float(f1),
    "per_class": report,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence_scores": y_conf
}
json_path = os.path.join(SAVE_DIR, "evaluation_results.json")
with open(json_path, "w") as f:
    json.dump(results, f, indent=4)
print(f"Evaluation results saved to {json_path}")

# CSV per-row
df_results = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})
csv_path = os.path.join(SAVE_DIR, "evaluation_results.csv")
df_results.to_csv(csv_path, index=False)
print(f"Per-row results saved to {csv_path}")

print("\n✅ Evaluation completed successfully!")
















second attempt



# ================================================
# Evaluation Script for Label Studio CSV
# Includes debug to see predictions and correct mapping
# ================================================

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns
import json
import ast
import os

# --------------------------
# CONFIGURATION - UPDATE THIS
# --------------------------
MODEL_PATH = "C:/path_to_your_model"        # trained model folder
CSV_PATH = "C:/path_to_your_csv/emails.csv" # Label Studio exported CSV
TEXT_COL = "text"                            # column containing email/text
LABEL_COL = "classification"                 # column containing taxonomy/label
SAVE_DIR = "C:/path_to_save_results"         # folder to save outputs

os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------
# FUNCTION TO EXTRACT READABLE LABEL
# --------------------------
def extract_label(cell_value):
    """
    Converts Label Studio classification column like:
    '[{"taxonomy":[["Internet Banking","Account Access","Unblock"]]}]'
    into readable label string:
    'Internet Banking > Account Access > Unblock'
    """
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except Exception as e:
        return "Unknown"

# --------------------------
# 1. LOAD MODEL
# --------------------------
print("Loading model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
print("Model loaded on", device)

# --------------------------
# 2. LOAD CSV
# --------------------------
print("Loading CSV...")
df = pd.read_csv(CSV_PATH)

# NEW CHANGE: debug CSV loading
print("Number of rows in CSV:", len(df))
print("Columns in CSV:", df.columns.tolist())
print("First 3 rows:")
print(df.head(3))

if TEXT_COL not in df.columns or LABEL_COL not in df.columns:
    raise ValueError(f"CSV must contain columns '{TEXT_COL}' and '{LABEL_COL}'")

texts = df[TEXT_COL].tolist()

# NEW CHANGE: Convert nested taxonomy JSON → readable labels for y_true
y_true = [extract_label(x) for x in df[LABEL_COL]]

print(f"Loaded {len(texts)} rows")

# --------------------------
# 3. GENERATE PREDICTIONS WITH DEBUG
# --------------------------
print("Generating predictions for first 20 rows...")  # NEW CHANGE
y_pred = []
y_conf = []

for idx, text in enumerate(texts):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits.cpu()  # NEW CHANGE: move logits to CPU

    pred_id = torch.argmax(logits, dim=-1).item()
    prob = torch.softmax(logits, dim=-1)[0][pred_id].item()

    y_pred.append(pred_id)
    y_conf.append(prob)

    # NEW CHANGE: Debug printing inside loop
    if idx < 20:  # only first 20 rows
        print(f"\nText {idx} preview: {text[:50]}...")
        print("y_true:", y_true[idx])
        print("pred_id:", pred_id)
        if hasattr(model.config, "id2label"):
            print("pred_label:", model.config.id2label.get(pred_id, "UNKNOWN"))
        print("confidence:", prob)

# --------------------------
# 4. MAP PREDICTIONS TO LABELS
# --------------------------
# NEW CHANGE: Map LABEL_0, LABEL_1 → actual taxonomy labels
if hasattr(model.config, "id2label") and all("LABEL_" not in v for v in model.config.id2label.values()):
    y_pred_labels = [model.config.id2label[p] for p in y_pred]
else:
    # ---- UPDATE THIS LIST ACCORDING TO TRAINING LABEL ORDER ----
    label_list = [
        "Internet Banking > Account Access > Unblock",
        "Internet Banking > Account Access > Block",
        "UPI > Transaction Failure",
        "Account > Balance Enquiry",
        # Add all labels used during training here
    ]
    y_pred_labels = [label_list[p] for p in y_pred]

# --------------------------
# 5. EVALUATION METRICS
# --------------------------
print("Computing metrics...")
report = classification_report(y_true, y_pred_labels, output_dict=True)
accuracy = accuracy_score(y_true, y_pred_labels)
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_labels, average='weighted')

print("\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred_labels))
print(f"Accuracy: {accuracy:.4f}")
print(f"Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

# --------------------------
# 6. CONFUSION MATRIX
# --------------------------
labels_sorted = sorted(list(set(y_true)))
cm = confusion_matrix(y_true, y_pred_labels, labels=labels_sorted)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=labels_sorted, yticklabels=labels_sorted)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
cm_path = os.path.join(SAVE_DIR, "confusion_matrix.png")
plt.savefig(cm_path)
plt.close()
print(f"Confusion matrix saved to {cm_path}")

# --------------------------
# 7. SAVE RESULTS
# --------------------------
results = {
    "accuracy": float(accuracy),
    "weighted_precision": float(precision),
    "weighted_recall": float(recall),
    "weighted_f1": float(f1),
    "per_class": report,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence_scores": y_conf
}
json_path = os.path.join(SAVE_DIR, "evaluation_results.json")
with open(json_path, "w") as f:
    json.dump(results, f, indent=4)
print(f"Evaluation results saved to {json_path}")

df_results = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})
csv_path = os.path.join(SAVE_DIR, "evaluation_results.csv")
df_results.to_csv(csv_path, index=False)
print(f"Per-row results saved to {csv_path}")

print("\n✅ Evaluation completed successfully!")























import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, confusion_matrix
import os

# =====================================================
# CONFIG — UPDATE ONLY THESE TWO
# =====================================================
MODEL_DIR = "model"              # folder where your trained model is stored
CSV_PATH = "your_export.csv"     # your evaluation CSV file path

TEXT_COL = "html"                # NEW CHANGE → your email message column
TRUE_COL = "classification"      # NEW CHANGE → your taxonomy label column
# =====================================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# =====================================================
# LOAD MODEL
# =====================================================
print("\nLoading model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)
model.eval()
print("Model loaded successfully.")

# =====================================================
# LOAD CSV
# =====================================================
print("\nLoading CSV...")
df = pd.read_csv(CSV_PATH)
print(f"Loaded {len(df)} rows.")
print("Columns:", df.columns.tolist())

texts = df[TEXT_COL].astype(str).tolist()
y_true = df[TRUE_COL].astype(str).tolist()

# =====================================================
# NEW CHANGE: AUTO-EXTRACT LABEL LIST FROM y_true
# =====================================================
print("\nExtracting label_list automatically from CSV...")
label_list = sorted(list(set(y_true)))     # NEW CHANGE
print(f"Found {len(label_list)} unique labels.")

# Build mappings
label2id = {label: idx for idx, label in enumerate(label_list)}     # NEW CHANGE
id2label = {idx: label for label, idx in label2id.items()}          # NEW CHANGE

print("\nSample label mapping:")
for i in range(min(10, len(id2label))):
    print(i, "→", id2label[i])

# =====================================================
# RUN PREDICTIONS
# =====================================================
print("\nRunning predictions...")
y_pred_ids = []
y_pred_probs = []

for idx, text in enumerate(texts):

    enc = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)

    with torch.no_grad():
        logits = model(**enc).logits.cpu()       # NEW CHANGE: force CPU for stable reading

    pred_id = torch.argmax(logits, dim=-1).item()
    prob = torch.softmax(logits, dim=-1)[0][pred_id].item()

    y_pred_ids.append(pred_id)
    y_pred_probs.append(prob)

    # NEW CHANGE: Debug first 5 predictions
    if idx < 5:
        print("\n--- DEBUG ROW", idx, "---")
        print("Email:", text[:120], "...")
        print("True label:   ", y_true[idx])
        print("Pred ID:      ", pred_id)
        print("Pred label:   ", id2label.get(pred_id, "UNKNOWN"))
        print("Confidence:   ", prob)

# =====================================================
# NEW CHANGE: MAP prediction IDs → REAL taxonomy labels
# =====================================================
y_pred = [id2label[p] for p in y_pred_ids]     # NEW CHANGE

# =====================================================
# SAVE OUTPUT FOR AUDIT TEAM
# =====================================================
df["y_pred"] = y_pred
df["confidence"] = y_pred_probs

output_file = "evaluation_output.csv"
df.to_csv(output_file, index=False)

print(f"\nSaved evaluation results to: {output_file}")

# =====================================================
# PRINT METRICS
# =====================================================
print("\n\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred, zero_division=0))

print("\n=== CONFUSION MATRIX (large!) ===")
print(confusion_matrix(y_true, y_pred))
