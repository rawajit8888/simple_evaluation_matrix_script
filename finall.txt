# ================================================
# Full Evaluation Script for Label Studio CSV
# Handles nested taxonomy automatically
# Generates predictions, metrics, and confusion matrix
# Safe: Offline, no backend interaction
# ================================================

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns
import json
import ast
import os

# --------------------------
# CONFIGURATION - UPDATE THIS
# --------------------------
MODEL_PATH = "C:/path_to_your_model"       # trained model folder
CSV_PATH = "C:/path_to_your_csv/emails.csv" # Label Studio exported CSV
TEXT_COL = "text"                           # column containing email/text
LABEL_COL = "classification"                # column containing taxonomy/label
SAVE_DIR = "C:/path_to_save_results"        # folder to save outputs

os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------
# FUNCTION TO EXTRACT READABLE LABEL
# --------------------------
def extract_label(cell_value):
    """
    Converts Label Studio classification column like:
    '[{"taxonomy":[["Internet Banking","Account Access","Unblock"]]}]'
    into readable label string:
    'Internet Banking > Account Access > Unblock'
    """
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except Exception as e:
        return "Unknown"

# --------------------------
# 1. LOAD MODEL
# --------------------------
print("Loading model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
print("Model loaded on", device)

# --------------------------
# 2. LOAD CSV
# --------------------------
print("Loading CSV...")
df = pd.read_csv(CSV_PATH)
if TEXT_COL not in df.columns or LABEL_COL not in df.columns:
    raise ValueError(f"CSV must contain columns '{TEXT_COL}' and '{LABEL_COL}'")

texts = df[TEXT_COL].tolist()
y_true = [extract_label(x) for x in df[LABEL_COL]]
print(f"Loaded {len(texts)} rows")

# --------------------------
# 3. GENERATE PREDICTIONS
# --------------------------
print("Generating predictions...")
y_pred = []
y_conf = []

for text in texts:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits
    pred_id = torch.argmax(logits, dim=-1).item()
    prob = torch.softmax(logits, dim=-1)[0][pred_id].item()
    y_pred.append(pred_id)
    y_conf.append(prob)

# Convert prediction ids to labels if model has mapping
if hasattr(model.config, "id2label"):
    y_pred_labels = [model.config.id2label[p] for p in y_pred]
else:
    y_pred_labels = y_pred

# --------------------------
# 4. EVALUATION METRICS
# --------------------------
print("Computing metrics...")
report = classification_report(y_true, y_pred_labels, output_dict=True)
accuracy = accuracy_score(y_true, y_pred_labels)
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_labels, average='weighted')

print("\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred_labels))
print(f"Accuracy: {accuracy:.4f}")
print(f"Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

# --------------------------
# 5. CONFUSION MATRIX
# --------------------------
labels_sorted = sorted(list(set(y_true)))
cm = confusion_matrix(y_true, y_pred_labels, labels=labels_sorted)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=labels_sorted, yticklabels=labels_sorted)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
cm_path = os.path.join(SAVE_DIR, "confusion_matrix.png")
plt.savefig(cm_path)
plt.close()
print(f"Confusion matrix saved to {cm_path}")

# --------------------------
# 6. SAVE RESULTS
# --------------------------
# JSON summary
results = {
    "accuracy": float(accuracy),
    "weighted_precision": float(precision),
    "weighted_recall": float(recall),
    "weighted_f1": float(f1),
    "per_class": report,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence_scores": y_conf
}
json_path = os.path.join(SAVE_DIR, "evaluation_results.json")
with open(json_path, "w") as f:
    json.dump(results, f, indent=4)
print(f"Evaluation results saved to {json_path}")

# CSV per-row
df_results = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})
csv_path = os.path.join(SAVE_DIR, "evaluation_results.csv")
df_results.to_csv(csv_path, index=False)
print(f"Per-row results saved to {csv_path}")

print("\n✅ Evaluation completed successfully!")
















second attempt



# ================================================
# Evaluation Script for Label Studio CSV
# Includes debug to see predictions and correct mapping
# ================================================

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns
import json
import ast
import os

# --------------------------
# CONFIGURATION - UPDATE THIS
# --------------------------
MODEL_PATH = "C:/path_to_your_model"        # trained model folder
CSV_PATH = "C:/path_to_your_csv/emails.csv" # Label Studio exported CSV
TEXT_COL = "text"                            # column containing email/text
LABEL_COL = "classification"                 # column containing taxonomy/label
SAVE_DIR = "C:/path_to_save_results"         # folder to save outputs

os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------
# FUNCTION TO EXTRACT READABLE LABEL
# --------------------------
def extract_label(cell_value):
    """
    Converts Label Studio classification column like:
    '[{"taxonomy":[["Internet Banking","Account Access","Unblock"]]}]'
    into readable label string:
    'Internet Banking > Account Access > Unblock'
    """
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except Exception as e:
        return "Unknown"

# --------------------------
# 1. LOAD MODEL
# --------------------------
print("Loading model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
print("Model loaded on", device)

# --------------------------
# 2. LOAD CSV
# --------------------------
print("Loading CSV...")
df = pd.read_csv(CSV_PATH)

# NEW CHANGE: debug CSV loading
print("Number of rows in CSV:", len(df))
print("Columns in CSV:", df.columns.tolist())
print("First 3 rows:")
print(df.head(3))

if TEXT_COL not in df.columns or LABEL_COL not in df.columns:
    raise ValueError(f"CSV must contain columns '{TEXT_COL}' and '{LABEL_COL}'")

texts = df[TEXT_COL].tolist()

# NEW CHANGE: Convert nested taxonomy JSON → readable labels for y_true
y_true = [extract_label(x) for x in df[LABEL_COL]]

print(f"Loaded {len(texts)} rows")

# --------------------------
# 3. GENERATE PREDICTIONS WITH DEBUG
# --------------------------
print("Generating predictions for first 20 rows...")  # NEW CHANGE
y_pred = []
y_conf = []

for idx, text in enumerate(texts):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits.cpu()  # NEW CHANGE: move logits to CPU

    pred_id = torch.argmax(logits, dim=-1).item()
    prob = torch.softmax(logits, dim=-1)[0][pred_id].item()

    y_pred.append(pred_id)
    y_conf.append(prob)

    # NEW CHANGE: Debug printing inside loop
    if idx < 20:  # only first 20 rows
        print(f"\nText {idx} preview: {text[:50]}...")
        print("y_true:", y_true[idx])
        print("pred_id:", pred_id)
        if hasattr(model.config, "id2label"):
            print("pred_label:", model.config.id2label.get(pred_id, "UNKNOWN"))
        print("confidence:", prob)

# --------------------------
# 4. MAP PREDICTIONS TO LABELS
# --------------------------
# NEW CHANGE: Map LABEL_0, LABEL_1 → actual taxonomy labels
if hasattr(model.config, "id2label") and all("LABEL_" not in v for v in model.config.id2label.values()):
    y_pred_labels = [model.config.id2label[p] for p in y_pred]
else:
    # ---- UPDATE THIS LIST ACCORDING TO TRAINING LABEL ORDER ----
    label_list = [
        "Internet Banking > Account Access > Unblock",
        "Internet Banking > Account Access > Block",
        "UPI > Transaction Failure",
        "Account > Balance Enquiry",
        # Add all labels used during training here
    ]
    y_pred_labels = [label_list[p] for p in y_pred]

# --------------------------
# 5. EVALUATION METRICS
# --------------------------
print("Computing metrics...")
report = classification_report(y_true, y_pred_labels, output_dict=True)
accuracy = accuracy_score(y_true, y_pred_labels)
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_labels, average='weighted')

print("\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred_labels))
print(f"Accuracy: {accuracy:.4f}")
print(f"Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

# --------------------------
# 6. CONFUSION MATRIX
# --------------------------
labels_sorted = sorted(list(set(y_true)))
cm = confusion_matrix(y_true, y_pred_labels, labels=labels_sorted)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=labels_sorted, yticklabels=labels_sorted)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
cm_path = os.path.join(SAVE_DIR, "confusion_matrix.png")
plt.savefig(cm_path)
plt.close()
print(f"Confusion matrix saved to {cm_path}")

# --------------------------
# 7. SAVE RESULTS
# --------------------------
results = {
    "accuracy": float(accuracy),
    "weighted_precision": float(precision),
    "weighted_recall": float(recall),
    "weighted_f1": float(f1),
    "per_class": report,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence_scores": y_conf
}
json_path = os.path.join(SAVE_DIR, "evaluation_results.json")
with open(json_path, "w") as f:
    json.dump(results, f, indent=4)
print(f"Evaluation results saved to {json_path}")

df_results = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})
csv_path = os.path.join(SAVE_DIR, "evaluation_results.csv")
df_results.to_csv(csv_path, index=False)
print(f"Per-row results saved to {csv_path}")

print("\n✅ Evaluation completed successfully!")























import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, confusion_matrix
import os

# =====================================================
# CONFIG — UPDATE ONLY THESE TWO
# =====================================================
MODEL_DIR = "model"              # folder where your trained model is stored
CSV_PATH = "your_export.csv"     # your evaluation CSV file path

TEXT_COL = "html"                # NEW CHANGE → your email message column
TRUE_COL = "classification"      # NEW CHANGE → your taxonomy label column
# =====================================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# =====================================================
# LOAD MODEL
# =====================================================
print("\nLoading model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)
model.eval()
print("Model loaded successfully.")

# =====================================================
# LOAD CSV
# =====================================================
print("\nLoading CSV...")
df = pd.read_csv(CSV_PATH)
print(f"Loaded {len(df)} rows.")
print("Columns:", df.columns.tolist())

texts = df[TEXT_COL].astype(str).tolist()
y_true = df[TRUE_COL].astype(str).tolist()

# =====================================================
# NEW CHANGE: AUTO-EXTRACT LABEL LIST FROM y_true
# =====================================================
print("\nExtracting label_list automatically from CSV...")
label_list = sorted(list(set(y_true)))     # NEW CHANGE
print(f"Found {len(label_list)} unique labels.")

# Build mappings
label2id = {label: idx for idx, label in enumerate(label_list)}     # NEW CHANGE
id2label = {idx: label for label, idx in label2id.items()}          # NEW CHANGE

print("\nSample label mapping:")
for i in range(min(10, len(id2label))):
    print(i, "→", id2label[i])

# =====================================================
# RUN PREDICTIONS
# =====================================================
print("\nRunning predictions...")
y_pred_ids = []
y_pred_probs = []

for idx, text in enumerate(texts):

    enc = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)

    with torch.no_grad():
        logits = model(**enc).logits.cpu()       # NEW CHANGE: force CPU for stable reading

    pred_id = torch.argmax(logits, dim=-1).item()
    prob = torch.softmax(logits, dim=-1)[0][pred_id].item()

    y_pred_ids.append(pred_id)
    y_pred_probs.append(prob)

    # NEW CHANGE: Debug first 5 predictions
    if idx < 5:
        print("\n--- DEBUG ROW", idx, "---")
        print("Email:", text[:120], "...")
        print("True label:   ", y_true[idx])
        print("Pred ID:      ", pred_id)
        print("Pred label:   ", id2label.get(pred_id, "UNKNOWN"))
        print("Confidence:   ", prob)

# =====================================================
# NEW CHANGE: MAP prediction IDs → REAL taxonomy labels
# =====================================================
y_pred = [id2label[p] for p in y_pred_ids]     # NEW CHANGE

# =====================================================
# SAVE OUTPUT FOR AUDIT TEAM
# =====================================================
df["y_pred"] = y_pred
df["confidence"] = y_pred_probs

output_file = "evaluation_output.csv"
df.to_csv(output_file, index=False)

print(f"\nSaved evaluation results to: {output_file}")

# =====================================================
# PRINT METRICS
# =====================================================
print("\n\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred, zero_division=0))

print("\n=== CONFUSION MATRIX (large!) ===")
print(confusion_matrix(y_true, y_pred))























# evaluate_labelstudio_final.py
# ================================================
# Full evaluation script (one-shot) for Label Studio CSV
# - Handles Label Studio taxonomy JSON in 'classification' column
# - Auto-builds label list from CSV (no manual typing)
# - Runs model predictions, maps IDs -> taxonomy labels
# - Prints debug for first rows, computes metrics, saves CSV/JSON and confusion matrix image
# - All important changes marked with "# >>> NEW CHANGE <<<"
# ================================================

import os
import json
import ast
import re
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score

# ------------------------
# CONFIG — MODIFY THESE
# ------------------------
MODEL_DIR = r"C:\path_to_your_model"            # <<< UPDATE THIS: folder with saved model
CSV_PATH = r"C:\path_to_your_csv\your_export.csv"   # <<< UPDATE THIS: path to Label Studio CSV
TEXT_COL = "html"          # <<< your text/email column name (you confirmed "html")
LABEL_COL = "classification"  # <<< your label column name (Label Studio JSON string)
SAVE_DIR = r"C:\path_to_save_results"   # <<< where results will be written
os.makedirs(SAVE_DIR, exist_ok=True)

# ------------------------
# Device
# ------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# >>> NEW CHANGE <<< Robust extractor for Label Studio taxonomy JSON strings
def extract_label(cell_value):
    """
    Parse Label Studio taxonomy JSON-like string into a readable label:
    Examples handled:
      '[{"taxonomy":[["Internet Banking","Account Access","Unblock"]]}]'
      or already flattened like 'Internet Banking > Account Access > Unblock'
    Returns a single string like: 'Internet Banking > Account Access > Unblock'
    If parsing fails, returns "Unknown".
    """
    if pd.isna(cell_value):
        return "Unknown"
    s = str(cell_value).strip()
    if s in ("", "[]"):
        return "Unknown"

    # If already flattened (contains >), return trimmed
    if ">" in s and "[" not in s:
        return s.strip()

    # Try JSON first (some exports use proper JSON quoting)
    try:
        parsed = json.loads(s)
        # Expect structure: [{"taxonomy":[["A","B","C"]]}]
        if isinstance(parsed, list) and parsed:
            first = parsed[0]
            if "taxonomy" in first and isinstance(first["taxonomy"], list) and first["taxonomy"]:
                tax = first["taxonomy"][0]
                if isinstance(tax, list):
                    return " > ".join([str(x).strip() for x in tax])
    except Exception:
        pass

    # Try ast.literal_eval (handles Python-style lists)
    try:
        parsed = ast.literal_eval(s)
        if isinstance(parsed, list) and parsed:
            first = parsed[0]
            if isinstance(first, dict) and "taxonomy" in first:
                taxlist = first["taxonomy"]
                if isinstance(taxlist, list) and taxlist:
                    first_tax = taxlist[0]
                    if isinstance(first_tax, list):
                        return " > ".join([str(x).strip() for x in first_tax])
    except Exception:
        pass

    # Fallback: try to extract items between quotes or words separated by commas inside brackets
    # e.g. [{"taxonomy":[[Internet Banking","Account Access", "Unblock"]]}]
    try:
        # extract text between the double quotes
        found = re.findall(r'"([^"]+)"', s)
        if found:
            return " > ".join([x.strip() for x in found])
        # fallback: words separated by commas inside brackets
        found2 = re.findall(r'\[\s*([^\]]+)\s*\]', s)
        if found2:
            parts = found2[-1].split(",")
            if len(parts) > 1:
                return " > ".join([p.strip().strip('"').strip("'") for p in parts])
    except Exception:
        pass

    return "Unknown"

# ------------------------
# Load CSV and preview
# ------------------------
print("\nLoading CSV:", CSV_PATH)
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"CSV file not found: {CSV_PATH}")

df = pd.read_csv(CSV_PATH, dtype=str, keep_default_na=False)  # read as strings, avoid NaN
print(f"Loaded rows: {len(df)}")
print("Columns:", df.columns.tolist())
if TEXT_COL not in df.columns or LABEL_COL not in df.columns:
    raise ValueError(f"CSV must contain columns '{TEXT_COL}' and '{LABEL_COL}'")

# >>> NEW CHANGE <<< clean text and labels
texts = df[TEXT_COL].fillna("").astype(str).tolist()
raw_labels = df[LABEL_COL].fillna("").astype(str).tolist()
clean_labels = [extract_label(x) for x in raw_labels]   # >>> NEW CHANGE <<< apply extractor
df["_clean_label"] = clean_labels                        # >>> NEW CHANGE <<< keep in df for debug/saving

print("\nSample cleaned labels (first 10):")
for i in range(min(10, len(clean_labels))):
    print(i, ":", clean_labels[i])

# ------------------------
# Auto-build label list from CSV
# ------------------------
# >>> NEW CHANGE <<< Build label list automatically from the cleaned labels
label_list = list(dict.fromkeys(clean_labels))  # preserve first-seen order (stable), do not sort
# remove "Unknown" if it dominates and keep as last if present
label_list = [lbl for lbl in label_list if lbl != "Unknown"] + (["Unknown"] if "Unknown" in label_list else [])
num_labels_csv = len(label_list)
print(f"\nAuto-extracted {num_labels_csv} unique labels from CSV (order = first-seen).")

# Print a small sample of mapping
print("Label sample (index -> label):")
for i, lbl in enumerate(label_list[:20]):
    print(f"{i} -> {lbl}")

# ------------------------
# Load model & tokenizer
# ------------------------
print("\nLoading model from:", MODEL_DIR)
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
model.eval()
model.to(device)
print("Model loaded. Model config num_labels:", getattr(model.config, "num_labels", None))

# Check model.config.id2label if present
model_id2label = {}
if hasattr(model.config, "id2label"):
    try:
        model_id2label = dict(model.config.id2label)
    except Exception:
        # sometimes id2label is a list-like; attempt conversion
        try:
            model_id2label = {int(k): v for k, v in model.config.id2label.items()}
        except Exception:
            model_id2label = {}

print("\nModel id2label preview (first 10):")
for k in list(model_id2label.keys())[:10]:
    print(k, "->", model_id2label[k])

# ------------------------
# Decide mapping strategy
# ------------------------
# >>> NEW CHANGE <<< mapping logic:
# 1) If model.config.id2label exists and values look like meaningful taxonomy (not 'LABEL_x'),
#    use that mapping.
# 2) Else, if number of labels in model equals number extracted from CSV, use CSV-extracted label_list (first-seen order).
# 3) Else, attempt safe fallback: use CSV-extracted labels but warn user.
use_model_id2label = False
if model_id2label:
    # check whether id2label values are just LABEL_0 etc.
    sample_vals = list(model_id2label.values())
    if all(isinstance(v, str) and v.startswith("LABEL_") for v in sample_vals):
        use_model_id2label = False
    else:
        use_model_id2label = True

mapping_info = {"strategy": None, "num_model_labels": getattr(model.config, "num_labels", None), "num_csv_labels": num_labels_csv}
if use_model_id2label:
    mapping_info["strategy"] = "use_model_id2label"
    print("\nMapping strategy: using model.config.id2label (values look meaningful).")
    id2label_map = {int(k): v for k, v in model_id2label.items()}
else:
    # try fallback: if model.num_labels matches CSV labels count, map index->csv label in first-seen order
    model_num = getattr(model.config, "num_labels", None)
    if model_num is not None and model_num == num_labels_csv:
        mapping_info["strategy"] = "use_csv_label_list_order"
        print("\nMapping strategy: model.num_labels equals number of CSV labels -> using CSV-extracted labels (first-seen order).")
        id2label_map = {idx: label_list[idx] for idx in range(num_labels_csv)}
    else:
        # final fallback: still map using CSV-extracted labels (may not match training order) but warn
        mapping_info["strategy"] = "fallback_use_csv_order_with_warning"
        print("\nWARNING: model.config.id2label not usable and model.num_labels != number of CSV labels.")
        print("Falling back to mapping prediction indices -> CSV-extracted labels in first-seen order.")
        print("If results look wrong, training-label-order must be retrieved to map correctly.")
        # ensure we can index; if model has fewer labels than CSV, truncate; if more, pad with Unknown
        model_num = getattr(model.config, "num_labels", None) or len(label_list)
        temp_list = label_list.copy()
        if len(temp_list) < model_num:
            # pad with "Unknown"
            temp_list += ["Unknown"] * (model_num - len(temp_list))
        id2label_map = {idx: temp_list[idx] for idx in range(model_num)}

# show mapping sample
print("\nFinal id2label_map sample (first 20):")
for k in sorted(list(id2label_map.keys()))[:20]:
    print(k, "->", id2label_map[k])

# ------------------------
# Run predictions (batched-safe loop) and debug-print first rows
# ------------------------
y_pred_ids = []
y_pred_labels = []
y_pred_probs = []

print("\nRunning inference over dataset...")
for idx, text in enumerate(texts):
    # Tokenize single example (keeps memory low)
    enc = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        outputs = model(**enc)
        logits = outputs.logits.detach().cpu()
    pred_id = int(torch.argmax(logits, dim=-1).item())
    prob = float(torch.softmax(logits, dim=-1)[0][pred_id].item())

    y_pred_ids.append(pred_id)
    mapped_label = id2label_map.get(pred_id, "Unknown")
    y_pred_labels.append(mapped_label)
    y_pred_probs.append(prob)

    # >>> NEW CHANGE <<< debug print for first 10 rows
    if idx < 10:
        print("\n--- DEBUG ROW", idx, "---")
        preview_text = text.replace("\n", " ")[:200]
        print("Text preview:", preview_text)
        print("y_true:", clean_labels[idx])
        print("pred_id:", pred_id)
        print("mapped pred label:", mapped_label)
        print("confidence:", prob)

# ------------------------
# Save per-row results
# ------------------------
df["_y_pred"] = y_pred_labels     # >>> NEW CHANGE <<<
df["_confidence"] = y_pred_probs  # >>> NEW CHANGE <<<
out_csv = os.path.join(SAVE_DIR, "evaluation_output.csv")
df.to_csv(out_csv, index=False)
print(f"\nSaved per-row results to: {out_csv}")

# ------------------------
# Compute and save metrics
# ------------------------
print("\nComputing metrics...")
# handle case where some y_true are "Unknown" (optionally drop them), but we will keep them
report_dict = classification_report(clean_labels, y_pred_labels, output_dict=True, zero_division=0)
report_text = classification_report(clean_labels, y_pred_labels, zero_division=0)
acc = accuracy_score(clean_labels, y_pred_labels)
prec, rec, f1, _ = precision_recall_fscore_support(clean_labels, y_pred_labels, average="weighted", zero_division=0)

print("\n=== CLASSIFICATION REPORT ===")
print(report_text)
print(f"\nAccuracy: {acc:.4f}")
print(f"Weighted Precision: {prec:.4f}, Weighted Recall: {rec:.4f}, Weighted F1: {f1:.4f}")

# confusion matrix (can be large)
labels_for_cm = list(dict.fromkeys(clean_labels))  # preserve order as first-seen
cm = confusion_matrix(clean_labels, y_pred_labels, labels=labels_for_cm)

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=False, fmt="d", cmap="Blues", xticklabels=labels_for_cm, yticklabels=labels_for_cm)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (rows=actual, cols=predicted)")
cm_path = os.path.join(SAVE_DIR, "confusion_matrix.png")
plt.tight_layout()
plt.savefig(cm_path, dpi=150)
plt.close()
print(f"\nSaved confusion matrix image to: {cm_path}")

# Save JSON summary
summary = {
    "mapping_info": mapping_info,
    "accuracy": float(acc),
    "weighted_precision": float(prec),
    "weighted_recall": float(rec),
    "weighted_f1": float(f1),
    "num_examples": len(clean_labels),
    "num_labels_csv": num_labels_csv,
    "model_num_labels": getattr(model.config, "num_labels", None),
    "sample_id2label": {k: id2label_map[k] for k in sorted(list(id2label_map.keys()))[:50]},
    "classification_report": report_dict
}
summary_path = os.path.join(SAVE_DIR, "evaluation_summary.json")
with open(summary_path, "w", encoding="utf-8") as f:
    json.dump(summary, f, indent=2, ensure_ascii=False)
print(f"\nSaved summary JSON to: {summary_path}")

print("\n✅ Evaluation finished. Inspect the CSV, JSON and confusion matrix in the save folder.")






#with encodres file 
# ===============================
# EVALUATION SCRIPT - BERT MODEL
# ===============================

import pandas as pd
import ast
import pickle
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from sklearn.metrics import classification_report
import torch

# --------------------------
# CONFIG / PATHS
# --------------------------
INPUT_CSV = "emails_dataset.csv"            # Label Studio exported CSV
ENCODER_FILE = "classification_sentiment.pkl"  # ML backend encoder
MODEL_DIR = "bert_model"                    # Trained HF model folder
TEXT_COL = "html"                           # Column containing email/text
LABEL_COL = "classification"                # Column containing Label Studio labels

# --------------------------
# HELPER FUNCTION
# --------------------------
def extract_label(cell_value):
    """Convert Label Studio taxonomy JSON to readable string"""
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except:
        return "Unknown"

# --------------------------
# LOAD DATA
# --------------------------
df = pd.read_csv(INPUT_CSV)
df["clean_label"] = df[LABEL_COL].apply(extract_label)
texts = df[TEXT_COL].tolist()
y_true = df["clean_label"].tolist()

print(f"Loaded {len(texts)} rows")
print(f"Unique labels in CSV: {df['clean_label'].nunique()}")

# --------------------------
# LOAD ENCODER
# --------------------------
with open(ENCODER_FILE, "rb") as f:
    encoder = pickle.load(f)  # encoder.classes_ contains all labels

print(f"Encoder loaded: {len(encoder.classes_)} labels")

# --------------------------
# LOAD MODEL
# --------------------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
model.eval()

# --------------------------
# RUN PREDICTIONS
# --------------------------
y_pred_ids = []
y_conf = []

for text in texts:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        pred_id = torch.argmax(logits, dim=-1).item()
        confidence = torch.softmax(logits, dim=-1)[0, pred_id].item()

    y_pred_ids.append(pred_id)
    y_conf.append(confidence)

# --------------------------
# MAP PREDICTIONS USING ENCODER
# --------------------------
y_pred_labels = [encoder.classes_[i] for i in y_pred_ids]

# --------------------------
# EVALUATION METRICS
# --------------------------
report = classification_report(y_true, y_pred_labels, zero_division=0)
print("\n===== CLASSIFICATION REPORT =====")
print(report)

# --------------------------
# SAVE RESULTS
# --------------------------
df_eval = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})

df_eval.to_csv("evaluation_results.csv", index=False)
print("Evaluation results saved to evaluation_results.csv")









encodrs 2nd aatempt

# ===============================
# FULL EVALUATION + DEBUG SCRIPT
# ===============================

import pandas as pd
import ast
import pickle
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from sklearn.metrics import classification_report
import torch

# --------------------------
# CONFIG / PATHS
# --------------------------
INPUT_CSV = "emails_dataset.csv"            # Label Studio exported CSV
ENCODER_FILE = "classification_sentiment.pkl"  # ML backend encoder
MODEL_DIR = "bert_model"                    # Trained HF model folder
TEXT_COL = "html"                           # Column containing email/text
LABEL_COL = "classification"                # Column containing Label Studio labels

# --------------------------
# HELPER FUNCTION
# --------------------------
def extract_label(cell_value):
    """Convert Label Studio taxonomy JSON to readable string"""
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except:
        return "Unknown"

# --------------------------
# LOAD DATA
# --------------------------
df = pd.read_csv(INPUT_CSV)
df["clean_label"] = df[LABEL_COL].apply(extract_label)
texts = df[TEXT_COL].tolist()
y_true = df["clean_label"].tolist()

print(f"Loaded {len(texts)} rows")
print(f"Unique labels in CSV: {df['clean_label'].nunique()}")

# --------------------------
# LOAD ENCODER
# --------------------------
with open(ENCODER_FILE, "rb") as f:
    encoder = pickle.load(f)  # NEW: Use encoder from ML backend
print(f"Encoder loaded: {len(encoder.classes_)} labels")

# --------------------------
# LOAD MODEL
# --------------------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
model.eval()
print(f"Model loaded: num_labels = {model.config.num_labels}")
print(f"Model id2label preview: {model.config.id2label}")  # NEW: check model mapping

# --------------------------
# RUN PREDICTIONS
# --------------------------
y_pred_ids = []
y_conf = []

for i, text in enumerate(texts):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        pred_id = torch.argmax(logits, dim=-1).item()
        confidence = torch.softmax(logits, dim=-1)[0, pred_id].item()

    y_pred_ids.append(pred_id)
    y_conf.append(confidence)

    # --------------------------
    # NEW: DEBUG FIRST 20 PREDICTIONS
    # --------------------------
    if i < 20:
        print("\n--- DEBUG ROW", i, "---")
        print(f"Text preview: {text[:50]}...")
        print("y_true:", y_true[i])
        print("pred_id:", pred_id)
        mapped_label = encoder.classes_[pred_id] if pred_id < len(encoder.classes_) else "INVALID"
        print("Mapped pred_label:", mapped_label)
        print("Confidence:", confidence)
        print("Logits shape:", logits.shape)
        print("Logits:", logits)

# --------------------------
# MAP PREDICTIONS USING ENCODER
# --------------------------
y_pred_labels = [encoder.classes_[i] if i < len(encoder.classes_) else "INVALID" for i in y_pred_ids]

# --------------------------
# COMPUTE METRICS
# --------------------------
report = classification_report(y_true, y_pred_labels, zero_division=0)
print("\n===== CLASSIFICATION REPORT =====")
print(report)

# --------------------------
# SAVE RESULTS
# --------------------------
df_eval = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})

df_eval.to_csv("evaluation_results.csv", index=False)
print("Evaluation results saved to evaluation_results.csv")

# --------------------------
# SUMMARY STATS
# --------------------------
print("\n--- SUMMARY ---")
print("Max pred_id:", max(y_pred_ids))
print("Min pred_id:", min(y_pred_ids))
print("Unique pred_ids:", set(y_pred_ids))
print("Number of labels in encoder:", len(encoder.classes_))





#load model method changes for num_labelks=2

# =======================================
# LOCAL EVALUATION SCRIPT - MULTITASK MODEL
# =======================================

import pandas as pd
import ast
import pickle
import torch
from sklearn.metrics import classification_report

# --------------------------
# IMPORT CUSTOM MULTITASK MODEL CLASS
# --------------------------
from multitaskmodel import MultitaskModel  # adjust if needed

# --------------------------
# CONFIG / PATHS
# --------------------------
INPUT_CSV = "emails_dataset.csv"               # Label Studio exported CSV
ENCODER_FILE = "classification_sentiment.pkl" # Encoder created after training
MODEL_DIR = "finetuned_multitask_model"       # Fine-tuned model folder
TEXT_COL = "html"                              # Column with email/text
LABEL_COL = "classification"                   # Column with Label Studio labels

# --------------------------
# HELPER FUNCTION TO CLEAN LABELS
# --------------------------
def extract_label(cell_value):
    """
    Convert Label Studio taxonomy JSON to readable string:
    '[{"taxonomy":[["Internet Banking","Account Access","Unblock"]]}]'
    -> 'Internet Banking > Account Access > Unblock'
    """
    if not cell_value or cell_value == "[]":
        return "Unknown"
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy_list = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy_list)
        return label
    except:
        return "Unknown"

# --------------------------
# LOAD DATA
# --------------------------
df = pd.read_csv(INPUT_CSV)
df["clean_label"] = df[LABEL_COL].apply(extract_label)
texts = df[TEXT_COL].tolist()
y_true = df["clean_label"].tolist()

print(f"Loaded {len(texts)} rows")
print(f"Unique labels in CSV: {df['clean_label'].nunique()}")

# --------------------------
# LOAD ENCODER
# --------------------------
with open(ENCODER_FILE, "rb") as f:
    encoder = pickle.load(f)
print(f"Encoder loaded: {len(encoder.classes_)} labels")

# --------------------------
# LOAD CUSTOM MULTITASK MODEL
# --------------------------
# NEW: Initialize with finetuned folder path
model = MultitaskModel(finetuned_model_path=MODEL_DIR)
model.eval()
print(f"Model loaded. Num labels: {model.num_labels}")  # should match encoder labels

# --------------------------
# RUN PREDICTIONS
# --------------------------
y_pred_ids = []
y_conf = []

for i, text in enumerate(texts):
    # Use internal tokenizer of multitask model
    inputs = model.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits  # raw logits
        pred_id = torch.argmax(logits, dim=-1).item()
        confidence = torch.softmax(logits, dim=-1)[0, pred_id].item()

    y_pred_ids.append(pred_id)
    y_conf.append(confidence)

    # --------------------------
    # DEBUG: Show first 20 predictions
    # --------------------------
    if i < 20:
        mapped_label = encoder.classes_[pred_id] if pred_id < len(encoder.classes_) else "INVALID"
        print("\n--- DEBUG ROW", i, "---")
        print(f"Text preview: {text[:50]}...")
        print("y_true:", y_true[i])
        print("pred_id:", pred_id)
        print("Mapped pred_label:", mapped_label)
        print("Confidence:", confidence)
        print("Logits shape:", logits.shape)
        print("Logits:", logits)

# --------------------------
# MAP PREDICTIONS USING ENCODER
# --------------------------
y_pred_labels = [encoder.classes_[i] if i < len(encoder.classes_) else "INVALID" for i in y_pred_ids]

# --------------------------
# COMPUTE CLASSIFICATION METRICS
# --------------------------
report = classification_report(y_true, y_pred_labels, zero_division=0)
print("\n===== CLASSIFICATION REPORT =====")
print(report)

# --------------------------
# SAVE RESULTS TO CSV
# --------------------------
df_eval = pd.DataFrame({
    "text": texts,
    "y_true": y_true,
    "y_pred": y_pred_labels,
    "confidence": y_conf
})
df_eval.to_csv("evaluation_results.csv", index=False)
print("Evaluation results saved to evaluation_results.csv")

# --------------------------
# SUMMARY STATS
# --------------------------
print("\n--- SUMMARY ---")
print("Max pred_id:", max(y_pred_ids))
print("Min pred_id:", min(y_pred_ids))
print("Unique pred_ids:", set(y_pred_ids))
print("Number of labels in encoder:", len(encoder.classes_))








#last attempt
import torch
import torch.nn as nn
from transformers import BertTokenizer
import pandas as pd
import ast
from sklearn.metrics import classification_report
import pickle

# -----------------------------
# 1. IMPORT YOUR MODEL CLASS
# -----------------------------
# NEW CHANGE: import your custom model
from multitaskmodel import MultitaskNNModel     # <-- adjust filename if needed

# -----------------------------
# 2. Paths 
# -----------------------------
MODEL_DIR = "fine_tuned_model_multitask"    # your saved model folder
ENCODER_PATH = f"{MODEL_DIR}/encoder/classification_sentiment.pkl"
CSV_PATH = "your_exported_labelstudio.csv"

# -----------------------------
# 3. Load Tokenizer
# -----------------------------
tokenizer = BertTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)

# -----------------------------
# 4. Load Encoder (CRITICAL)
# -----------------------------
with open(ENCODER_PATH, "rb") as f:
    encoder = pickle.load(f)

id2label = {v: k for k, v in encoder["classification"]["encoder"].items()}
num_labels = len(id2label)

print("Loaded encoder labels:", num_labels)

# -----------------------------
# 5. Load Your Real Model
# -----------------------------
# NEW CHANGE: match constructor EXACTLY
model = MultitaskNNModel(
    modelname=MODEL_DIR,
    classificationlabel_length=num_labels
)

# NEW CHANGE: load state dict
state_dict = torch.load(f"{MODEL_DIR}/pytorch_model.bin", map_location="cpu")
model.load_state_dict(state_dict, strict=False)
model.eval()

print("Model loaded with classifier head size:", model.classifier.out_features)

# -----------------------------
# 6. Load CSV and Extract y_true
# -----------------------------
df = pd.read_csv(CSV_PATH)

def extract_label(cell_value):
    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy = parsed[0]["taxonomy"][0]
        return " > ".join(taxonomy)
    except:
        return None

df["y_true"] = df["classification"].apply(extract_label)
df = df[df["y_true"].notna()]

texts = df["html"].tolist()
y_true = df["y_true"].tolist()

print("Loaded rows:", len(texts))

# -----------------------------
# 7. Predict
# -----------------------------
y_pred_ids = []
y_pred_labels = []

for txt in texts:
    inputs = tokenizer(txt, return_tensors="pt", truncation=True, padding=True, max_length=256)

    with torch.no_grad():
        bert_out = model.bert(**inputs)
        pooled = bert_out.last_hidden_state[:,0,:]
        logits = model.classifier(model.dropout(pooled))

    pred_id = torch.argmax(logits, dim=1).item()
    pred_label = id2label[pred_id]

    y_pred_ids.append(pred_id)
    y_pred_labels.append(pred_label)

# -----------------------------
# 8. Evaluation
# -----------------------------
print("\n=== Classification Report ===")
print(classification_report(y_true, y_pred_labels))

