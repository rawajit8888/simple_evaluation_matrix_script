# ============================================================
# FULL EVALUATION SCRIPT (FINAL FIXED VERSION)
# ============================================================

import pandas as pd
import torch
from torch.utils.data import DataLoader, TensorDataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pickle
from sklearn.metrics import classification_report
from torch.nn import functional as F
import json
import ast
import re

# ============================================================
# 1. CONFIG
# ============================================================
CSV_FILE = "your_data.csv"
TEXT_COLUMN = "Subject"
LABEL_COLUMN = "classification"
MODEL_DIR = "path_to_trained_model"
ENCODER_FILE = "encoders/classification.labels.pkl"
BATCH_SIZE = 16

# ============================================================
# 2. LOAD LABEL ENCODER
# ============================================================
with open(ENCODER_FILE, "rb") as f:
    label_encoder = pickle.load(f)

classes = list(label_encoder.classes_)
print("Original classes:", len(classes))

# --- ADD UNKNOWN IF MISSING ---
if "Unknown" not in classes:
    print("Adding 'Unknown' label to encoder...")
    classes.append("Unknown")
    label_encoder.classes_ = np.array(classes)

num_labels = len(label_encoder.classes_)
print("Updated classes:", num_labels)

# ============================================================
# 3. ULTRA ROBUST TAXONOMY PARSER
# ============================================================

def extract_label(cell_value):
    """
    Safely extracts taxonomy -> 'A > B > C'
    Returns 'Unknown' for corrupt, missing, or inconsistent values.
    """
    if not isinstance(cell_value, str) or cell_value.strip() == "" or cell_value == "[]":
        return "Unknown"

    try:
        parsed = ast.literal_eval(cell_value)
        taxonomy = parsed[0]["taxonomy"][0]
        label = " > ".join(taxonomy)

        if label.strip() == "":
            return "Unknown"
        return label
    
    except:
        return "Unknown"

# ============================================================
# 4. LOAD CSV & FIX LABELS
# ============================================================
df = pd.read_csv(CSV_FILE)

print("\nFixing taxonomy labels...")
df["fixed_label"] = df[LABEL_COLUMN].apply(extract_label)

# ============================================================
# 5. SAFE TRANSFORM â€” NO MORE ERRORS
# ============================================================

def safe_transform(label):
    """
    Convert label -> ID 
    If unseen, convert to 'Unknown'
    """
    if label not in label_encoder.classes_:
        print(f"[WARNING] Unseen label found: {label} -> forcing 'Unknown'")
        label = "Unknown"
    return label_encoder.transform([label])[0]

df["label_id"] = df["fixed_label"].apply(safe_transform)

print("Total usable rows:", len(df))

# ============================================================
# 6. LOAD MODEL
# ============================================================
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_DIR,
    num_labels=num_labels
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# ============================================================
# 7. PREPARE DATA
# ============================================================
texts = df[TEXT_COLUMN].astype(str).tolist()
labels = df["label_id"].tolist()

encodings = tokenizer(
    texts,
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt"
)

dataset = TensorDataset(
    encodings["input_ids"],
    encodings["attention_mask"],
    torch.tensor(labels)
)

loader = DataLoader(dataset, batch_size=BATCH_SIZE)

# ============================================================
# 8. RUN INFERENCE
# ============================================================
all_preds = []

print("\nRunning inference...")
with torch.no_grad():
    for batch in loader:
        input_ids, attention_mask, _ = [t.to(device) for t in batch]
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        probs = F.softmax(outputs.logits, dim=1)
        preds = torch.argmax(probs, dim=1)
        all_preds.extend(preds.cpu().numpy())

# ============================================================
# 9. MAP PREDICTIONS BACK
# ============================================================
df["y_pred"] = label_encoder.inverse_transform(all_preds)

# ============================================================
# 10. METRICS
# ============================================================
print("\n========== CLASSIFICATION REPORT ==========\n")
print(classification_report(df["fixed_label"], df["y_pred"], digits=4, zero_division=0))

# ============================================================
# 11. SAVE RESULTS
# ============================================================
df.to_csv("evaluation_results.csv", index=False)
print("\nSaved predictions to evaluation_results.csv")
