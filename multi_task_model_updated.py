import os
import pathlib
import re
import numpy as np
import pandas as pd
from tqdm import tqdm
import time
from datetime import datetime, timedelta

import label_studio_sdk
import logging

# QueryTypeNNModel and DepartmentNNModel are now defined in this file (below) - no separate import needed

from typing import List, Dict, Optional
from label_studio_ml.model import LabelStudioMLBase
from label_studio_ml.response import ModelResponse

import torch
import torch.optim as optim
import torch.nn as nn

from torch.utils.data import TensorDataset
from torch.utils.data import DataLoader
from torch.utils.data import RandomSampler
from torch.utils.data import SequentialSampler

from keras.utils import pad_sequences
from transformers import pipeline, Pipeline, BertModel
from transformers import AdamW
from itertools import groupby
from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer, AdamW
from transformers import DataCollatorForTokenClassification
from datasets import Dataset, ClassLabel, Value, Sequence, Features
from functools import partial
from dataprocessing.processlabels import ProcessLabels
from multitask_nn_model import MultiTaskNNModel
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import pickle

logger = logging.getLogger(__name__)


# ========== DepartmentNNModel Class (Level 2 Model) ==========

class DepartmentNNModel(nn.Module):
    """
    Department classification model with bundled label encoder.
    Level 2: MasterDepartment â†’ Department
    Uses same BERT backbone as MultiTask model for consistency.
    """
    
    def __init__(self, modelname, num_labels):
        super(DepartmentNNModel, self).__init__()
        
        # Use SAME backbone type as MultiTaskNNModel
        self.bert = BertModel.from_pretrained(modelname)
        self.dropout = nn.Dropout(0.2)  # increased 0.1 â†’ 0.2 for better generalisation
        self.classifier = nn.Linear(
            self.bert.config.hidden_size,
            num_labels
        )
        
        # Store encoder (will be set during training)
        self.encoder = None
        
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(
            input_ids,
            attention_mask=attention_mask
        )
        
        pooled_output = outputs[1]  # CLS pooled output
        pooled_output = self.dropout(pooled_output)
        
        logits = self.classifier(pooled_output)
        return logits
    
    def set_encoder(self, encoder):
        """Set label encoder before saving"""
        self.encoder = encoder
        logger.info("âœ“ Encoder attached to Department model")
    
    def save(self, directorypath):
        """Save model with bundled encoder"""
        try:
            os.makedirs(directorypath, exist_ok=True)
            
            # Save BERT backbone
            logger.info(f"ðŸ“¦ Saving Department BERT to {directorypath}")
            self.bert.save_pretrained(directorypath)
            
            # Save classifier head
            classifier_path = os.path.join(directorypath, "department_classifier.pth")
            logger.info(f"ðŸ’¾ Saving classifier head to {classifier_path}")
            torch.save(
                self.classifier.state_dict(),
                classifier_path
            )
            
            # Save bundled encoder
            encoder_path = os.path.join(directorypath, 'department_encoder.pkl')
            logger.info(f"ðŸ’¾ Saving department encoder to {encoder_path}")
            with open(encoder_path, 'wb') as f:
                pickle.dump(self.encoder, f)
            
            logger.info("âœ… Department model and encoder saved successfully")
            
        except Exception as e:
            logger.error(f"âŒ Error saving Department model: {e}")
            raise
    
    def load(self, directorypath):
        """Load model with bundled encoder"""
        try:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # Reload BERT
            logger.info(f"ðŸ“‚ Loading Department BERT from {directorypath}")
            self.bert = BertModel.from_pretrained(directorypath)
            
            # Reload classifier head
            classifier_path = os.path.join(directorypath, "department_classifier.pth")
            logger.info(f"ðŸ“‚ Loading classifier head from {classifier_path}")
            self.classifier.load_state_dict(
                torch.load(
                    classifier_path,
                    map_location=device
                )
            )
            
            # Load bundled encoder
            encoder_path = os.path.join(directorypath, 'department_encoder.pkl')
            if os.path.exists(encoder_path):
                logger.info(f"ðŸ“‚ Loading bundled department encoder from {encoder_path}")
                with open(encoder_path, 'rb') as f:
                    self.encoder = pickle.load(f)
                logger.info("âœ… Department model and encoder loaded successfully")
            else:
                logger.warning("âš ï¸  No bundled encoder found for Department - using external encoder")
            
            self.eval()
            
        except Exception as e:
            logger.error(f"âŒ Error loading Department model: {e}")
            raise
    
    def get_encoder(self):
        """Safely retrieve encoder"""
        if self.encoder is None:
            raise ValueError("Department encoder is None")
        return self.encoder


# ========== QueryTypeNNModel Class (Level 3 Model) ==========

class QueryTypeNNModel(nn.Module):
    """
    QueryType classification model with bundled label encoder.
    Level 3: Department â†’ QueryType
    Uses same BERT backbone as MultiTask model for consistency.
    """
    
    def __init__(self, modelname, num_labels):
        super(QueryTypeNNModel, self).__init__()
        
        # Use SAME backbone type as MultiTaskNNModel
        self.bert = BertModel.from_pretrained(modelname)
        self.dropout = nn.Dropout(0.2)  # increased 0.1 â†’ 0.2 for better generalisation
        self.classifier = nn.Linear(
            self.bert.config.hidden_size,
            num_labels
        )
        
        # Store encoder (will be set during training)
        self.encoder = None
        
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(
            input_ids,
            attention_mask=attention_mask
        )
        
        pooled_output = outputs[1]  # CLS pooled output
        pooled_output = self.dropout(pooled_output)
        
        logits = self.classifier(pooled_output)
        return logits
    
    def set_encoder(self, encoder):
        """Set label encoder before saving"""
        self.encoder = encoder
        logger.info("âœ“ Encoder attached to QueryType model")
    
    def save(self, directorypath):
        """Save model with bundled encoder"""
        try:
            os.makedirs(directorypath, exist_ok=True)
            
            # Save BERT backbone
            logger.info(f"ðŸ“¦ Saving QueryType BERT to {directorypath}")
            self.bert.save_pretrained(directorypath)
            
            # Save classifier head
            classifier_path = os.path.join(directorypath, "querytype_classifier.pth")
            logger.info(f"ðŸ’¾ Saving classifier head to {classifier_path}")
            torch.save(
                self.classifier.state_dict(),
                classifier_path
            )
            
            # Save bundled encoder
            encoder_path = os.path.join(directorypath, 'querytype_encoder.pkl')
            logger.info(f"ðŸ’¾ Saving querytype encoder to {encoder_path}")
            with open(encoder_path, 'wb') as f:
                pickle.dump(self.encoder, f)
            
            logger.info("âœ… QueryType model and encoder saved successfully")
            
        except Exception as e:
            logger.error(f"âŒ Error saving QueryType model: {e}")
            raise
    
    def load(self, directorypath):
        """Load model with bundled encoder"""
        try:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # Reload BERT
            logger.info(f"ðŸ“‚ Loading QueryType BERT from {directorypath}")
            self.bert = BertModel.from_pretrained(directorypath)
            
            # Reload classifier head
            classifier_path = os.path.join(directorypath, "querytype_classifier.pth")
            logger.info(f"ðŸ“‚ Loading classifier head from {classifier_path}")
            self.classifier.load_state_dict(
                torch.load(
                    classifier_path,
                    map_location=device
                )
            )
            
            # Load bundled encoder
            encoder_path = os.path.join(directorypath, 'querytype_encoder.pkl')
            if os.path.exists(encoder_path):
                logger.info(f"ðŸ“‚ Loading bundled querytype encoder from {encoder_path}")
                with open(encoder_path, 'rb') as f:
                    self.encoder = pickle.load(f)
                logger.info("âœ… QueryType model and encoder loaded successfully")
            else:
                logger.warning("âš ï¸  No bundled encoder found for QueryType - using external encoder")
            
            self.eval()
            
        except Exception as e:
            logger.error(f"âŒ Error loading QueryType model: {e}")
            raise
    
    def get_encoder(self):
        """Safely retrieve encoder"""
        if self.encoder is None:
            raise ValueError("QueryType encoder is None")
        return self.encoder


# ========== Simple Single-Task Model (Level 1) ==========

class MasterDepartmentModel(nn.Module):
    """
    Simple single-task model for MasterDepartment classification.
    Level 1: Email â†’ MasterDepartment ONLY
    """
    
    def __init__(self, modelname, num_labels):
        super(MasterDepartmentModel, self).__init__()
        
        self.bert = BertModel.from_pretrained(modelname)
        self.dropout = nn.Dropout(0.2)  # increased 0.1 â†’ 0.2 for better generalisation
        self.classifier = nn.Linear(
            self.bert.config.hidden_size,
            num_labels
        )
        
        # Store encoder
        self.encoder = None
        
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(
            input_ids,
            attention_mask=attention_mask
        )
        
        pooled_output = outputs[1]  # CLS pooled output
        pooled_output = self.dropout(pooled_output)
        
        logits = self.classifier(pooled_output)
        return logits
    
    def set_encoder(self, encoder):
        """Set label encoder before saving"""
        self.encoder = encoder
        logger.info("âœ“ Encoder attached to MasterDepartment model")
    
    def save(self, directorypath):
        """Save model with bundled encoder"""
        try:
            os.makedirs(directorypath, exist_ok=True)
            
            # Save BERT backbone
            logger.info(f"ðŸ“¦ Saving MasterDepartment BERT to {directorypath}")
            self.bert.save_pretrained(directorypath)
            
            # Save classifier head
            classifier_path = os.path.join(directorypath, "masterdepartment_classifier.pth")
            logger.info(f"ðŸ’¾ Saving classifier head to {classifier_path}")
            torch.save(
                self.classifier.state_dict(),
                classifier_path
            )
            
            # Save bundled encoder
            encoder_path = os.path.join(directorypath, 'masterdepartment_encoder.pkl')
            logger.info(f"ðŸ’¾ Saving masterdepartment encoder to {encoder_path}")
            with open(encoder_path, 'wb') as f:
                pickle.dump(self.encoder, f)
            
            logger.info("âœ… MasterDepartment model and encoder saved successfully")
            
        except Exception as e:
            logger.error(f"âŒ Error saving MasterDepartment model: {e}")
            raise
    
    def load(self, directorypath):
        """Load model with bundled encoder"""
        try:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # Reload BERT
            logger.info(f"ðŸ“‚ Loading MasterDepartment BERT from {directorypath}")
            self.bert = BertModel.from_pretrained(directorypath)
            
            # Reload classifier head
            classifier_path = os.path.join(directorypath, "masterdepartment_classifier.pth")
            logger.info(f"ðŸ“‚ Loading classifier head from {classifier_path}")
            self.classifier.load_state_dict(
                torch.load(
                    classifier_path,
                    map_location=device
                )
            )
            
            # Load bundled encoder
            encoder_path = os.path.join(directorypath, 'masterdepartment_encoder.pkl')
            if os.path.exists(encoder_path):
                logger.info(f"ðŸ“‚ Loading bundled masterdepartment encoder from {encoder_path}")
                with open(encoder_path, 'rb') as f:
                    self.encoder = pickle.load(f)
                logger.info("âœ… MasterDepartment model and encoder loaded successfully")
            else:
                logger.warning("âš ï¸  No bundled encoder found for MasterDepartment")
            
            self.eval()
            
        except Exception as e:
            logger.error(f"âŒ Error loading MasterDepartment model: {e}")
            raise
    
    def get_encoder(self):
        """Safely retrieve encoder"""
        if self.encoder is None:
            raise ValueError("MasterDepartment encoder is None")
        return self.encoder


# ========== TrainingLogger Class ==========

class TrainingLogger:
    """Enhanced training logger with time estimates"""
    
    def __init__(self, logger, total_epochs, total_batches):
        self.logger = logger
        self.total_epochs = total_epochs
        self.total_batches = total_batches
        self.start_time = None
        self.epoch_times = []
        
    def start_training(self, model_name="Model"):
        """Mark training start"""
        self.start_time = time.time()
        self.logger.info("=" * 80)
        self.logger.info(f"ðŸš€ {model_name} TRAINING STARTED")
        self.logger.info(f"ðŸ“Š Total Epochs: {self.total_epochs}")
        self.logger.info(f"ðŸ“¦ Total Batches per Epoch: {self.total_batches}")
        self.logger.info(f"â° Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("=" * 80)
        
    def start_epoch(self, epoch):
        """Mark epoch start"""
        self.epoch_start = time.time()
        self.logger.info("")
        self.logger.info(f"ðŸ“ˆ EPOCH {epoch + 1}/{self.total_epochs}")
        self.logger.info("-" * 80)
        
    def log_batch(self, epoch, batch_idx, loss, **extra_losses):
        """Log batch progress"""
        if batch_idx % 10 == 0:  # Log every 10 batches
            progress = (batch_idx / self.total_batches) * 100
            loss_str = f"Loss: {loss:.4f}"
            
            # Add extra losses if provided
            for name, value in extra_losses.items():
                loss_str += f" | {name}: {value:.4f}"
            
            self.logger.info(
                f"  Batch {batch_idx}/{self.total_batches} ({progress:.1f}%) | {loss_str}"
            )
    
    def end_epoch(self, epoch, avg_loss):
        """Mark epoch end and estimate remaining time"""
        epoch_time = time.time() - self.epoch_start
        self.epoch_times.append(epoch_time)
        
        # Calculate ETA
        avg_epoch_time = np.mean(self.epoch_times)
        remaining_epochs = self.total_epochs - (epoch + 1)
        eta_seconds = avg_epoch_time * remaining_epochs
        eta = timedelta(seconds=int(eta_seconds))
        
        self.logger.info("-" * 80)
        self.logger.info(
            f"âœ“ Epoch {epoch + 1} complete | "
            f"Avg Loss: {avg_loss:.4f} | "
            f"Time: {epoch_time:.2f}s | "
            f"ETA: {eta}"
        )
    
    def end_training(self):
        """Mark training end"""
        total_time = time.time() - self.start_time
        self.logger.info("=" * 80)
        self.logger.info(f"ðŸŽ‰ TRAINING COMPLETE")
        self.logger.info(f"â±ï¸  Total Time: {timedelta(seconds=int(total_time))}")
        self.logger.info("=" * 80)


# ========== MultiTaskBertModel Class ==========

class MultiTaskBertModel:
    """
    3-Level Hierarchical Email Classification System
    
    Features:
    - Level 1: Email â†’ MasterDepartment ONLY
    - Level 2: Email + MasterDepartment â†’ Department
    - Level 3: Email + MasterDepartment + Department â†’ QueryType
    - Bundled encoders (risk-free deployment)
    - Comprehensive logging
    - Automatic inference routing
    """
    
    def __init__(self, config, logger):
        self.logger = logger
        self.config = config
        self.model_dir = config.get('MODEL_DIR', './results/bert-classification-sentiment3level_training')
        
        # CRITICAL FIX: Use actual local model path or valid HuggingFace model
        # Check if lsmb-base-model exists locally, otherwise use bert-base-uncased
        local_model_path = os.path.join(self.model_dir, 'lsmb-base-model')
        if os.path.exists(local_model_path):
            self.baseline_model_name = local_model_path
            self.logger.info(f"âœ“ Using LOCAL model: {local_model_path}")
        else:
            self.baseline_model_name = 'bert-base-uncased'
            self.logger.warning(f"âš ï¸  Local model not found, using HuggingFace: {self.baseline_model_name}")
        
        self.finetuned_model_name = config.get('FINETUNED_MODEL_NAME', 'masterdepartment_model')
        
        # Initialize models as None
        self.model = None              # Level 1 model (MasterDepartment ONLY)
        self.department_model = None   # Level 2 model
        self.querytype_model = None    # Level 3 model
        self.tokenizer = None
        
        # Will be injected from model.py
        self.label_interface = None
        self.processed_label_encoders = None
        self.preload_task_data = None
        
        self.logger.info("âœ“ MultiTaskBertModel instance created")
    
    def reload_model(self):
        """
        Load all three models:
        - Level 1: MasterDepartment
        - Level 2: Department
        - Level 3: QueryType
        """
        self.logger.info("ðŸ”„ Reloading all models...")
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.logger.info(f"ðŸ–¥ï¸  Using device: {device}")
        
        # ========== LOAD TOKENIZER ==========
        from transformers import AutoTokenizer
        
        tokenizer_path = os.path.join(self.model_dir, self.finetuned_model_name)
        if not os.path.exists(tokenizer_path):
            tokenizer_path = self.baseline_model_name
            
        self.logger.info(f"ðŸ“‚ Loading tokenizer from: {tokenizer_path}")
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)
            self.logger.info("âœ“ Tokenizer loaded from local files")
        except Exception as e:
            self.logger.warning(f"âš ï¸  Failed to load tokenizer locally: {e}")
            self.logger.info(f"ðŸ“¥ Downloading tokenizer from: {tokenizer_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)
        
        # ========== LOAD LEVEL 1 MODEL (MasterDepartment ONLY) ==========
        masterdept_path = os.path.join(self.model_dir, self.finetuned_model_name)
        
        if os.path.exists(masterdept_path):
            self.logger.info(f"ðŸ“‚ Loading Level 1 model from: {masterdept_path}")
            
            # Load encoder to get label count
            encoder_path = os.path.join(masterdept_path, 'masterdepartment_encoder.pkl')
            if os.path.exists(encoder_path):
                with open(encoder_path, 'rb') as f:
                    encoder = pickle.load(f)
                num_masterdept = len(encoder.classes_)
            else:
                num_masterdept = 100  # default
            
            self.model = MasterDepartmentModel(
                self.baseline_model_name,
                num_labels=num_masterdept
            )
            self.model.load(masterdept_path)
            self.model.to(device)
            self.model.eval()
            
            self.logger.info(f"âœ… Level 1 model loaded | MasterDepartments: {num_masterdept}")
        else:
            self.logger.warning(f"âš ï¸  Level 1 model not found at {masterdept_path} - will be created during training")
        
        # ========== LOAD LEVEL 2 MODEL (Department) ==========
        department_path = os.path.join(self.model_dir, "department_model")
        
        if os.path.exists(department_path):
            self.logger.info(f"ðŸ“‚ Loading Level 2 (Department) model from: {department_path}")
            
            # Load encoder to get label count
            dept_encoder_path = os.path.join(department_path, 'department_encoder.pkl')
            if os.path.exists(dept_encoder_path):
                with open(dept_encoder_path, 'rb') as f:
                    dept_encoder = pickle.load(f)
                num_departments = len(dept_encoder.classes_)
            else:
                num_departments = 100  # default
            
            self.department_model = DepartmentNNModel(
                self.baseline_model_name,
                num_labels=num_departments
            )
            self.department_model.load(department_path)
            self.department_model.to(device)
            self.department_model.eval()
            
            self.logger.info(f"âœ… Level 2 model loaded | Departments: {num_departments}")
        else:
            self.logger.warning(f"âš ï¸  Level 2 (Department) model not found at {department_path} - will be created during training")
        
        # ========== LOAD LEVEL 3 MODEL (QueryType) ==========
        querytype_path = os.path.join(self.model_dir, "querytype_model")
        
        if os.path.exists(querytype_path):
            self.logger.info(f"ðŸ“‚ Loading Level 3 (QueryType) model from: {querytype_path}")
            
            # Load encoder to get label count
            qt_encoder_path = os.path.join(querytype_path, 'querytype_encoder.pkl')
            if os.path.exists(qt_encoder_path):
                with open(qt_encoder_path, 'rb') as f:
                    qt_encoder = pickle.load(f)
                num_querytypes = len(qt_encoder.classes_)
            else:
                num_querytypes = 100  # default
            
            self.querytype_model = QueryTypeNNModel(
                self.baseline_model_name,
                num_labels=num_querytypes
            )
            self.querytype_model.load(querytype_path)
            self.querytype_model.to(device)
            self.querytype_model.eval()
            
            self.logger.info(f"âœ… Level 3 model loaded | QueryTypes: {num_querytypes}")
        else:
            self.logger.warning(f"âš ï¸  Level 3 (QueryType) model not found at {querytype_path} - will be created during training")
        
        self.logger.info("ðŸŽ‰ Model loading complete")
    
    # ========== HELPER FUNCTIONS ==========
    
    def _get_device(self):
        """Get available device (CUDA or CPU)"""
        return torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def _tokenize_and_pad(self, texts, tokenizer, max_len):
        """Tokenize and pad text sequences"""
        input_ids = []
        for text in texts:
            encoded = tokenizer.encode(
                text,
                add_special_tokens=True,
                max_length=max_len,
                truncation=True
            )
            input_ids.append(encoded)
        
        # Pad sequences
        input_ids = pad_sequences(
            input_ids,
            maxlen=max_len,
            dtype="long",
            value=0,
            truncating="post",
            padding="post"
        )
        
        # Create attention masks
        attention_masks = []
        for seq in input_ids:
            mask = [int(token_id > 0) for token_id in seq]
            attention_masks.append(mask)
        
        return input_ids, attention_masks
    
    def _create_dataloader(self, input_ids, attention_masks, labels=None, batch_size=16, shuffle=True):
        """Create DataLoader from tensors"""
        inputs = torch.tensor(input_ids)
        masks = torch.tensor(attention_masks)
        
        if labels is not None:
            labels_tensor = torch.tensor(labels)
            dataset = TensorDataset(inputs, masks, labels_tensor)
        else:
            dataset = TensorDataset(inputs, masks)
        
        sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)
        dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)
        
        return dataloader
    
    def _decode_predictions(self, predictions, task_name):
        """Decode numerical predictions to labels"""
        if task_name == 'masterdepartment':
            if self.model is None:
                raise ValueError("MasterDepartment model not loaded")
            encoder = self.model.get_encoder()
        elif task_name == 'department':
            if self.department_model is None:
                raise ValueError("Department model not loaded")
            encoder = self.department_model.get_encoder()
        elif task_name == 'querytype':
            if self.querytype_model is None:
                raise ValueError("QueryType model not loaded")
            encoder = self.querytype_model.get_encoder()
        else:
            raise ValueError(f"Unknown task: {task_name}")
        
        # Convert to numpy if tensor
        if torch.is_tensor(predictions):
            predictions = predictions.cpu().numpy()
        
        # Decode
        decoded = encoder.inverse_transform(predictions)
        return decoded.tolist() if hasattr(decoded, 'tolist') else list(decoded)
    
    # ========== DATABASE FUNCTIONS ==========
    
    def init_metrics_db(self):
        """Initialize SQLite database for metrics"""
        import sqlite3
        
        db_path = os.path.join(self.model_dir, "metrics.db")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Create runs table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS runs (
                run_id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                level INTEGER,
                train_samples INTEGER,
                test_samples INTEGER
            )
        """)
        
        # Create metrics table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                run_id INTEGER,
                task TEXT,
                metric TEXT,
                value REAL,
                FOREIGN KEY (run_id) REFERENCES runs(run_id)
            )
        """)
        
        conn.commit()
        conn.close()
        
        self.logger.info(f"âœ“ Metrics database initialized at {db_path}")
    
    def save_metrics_to_sqlite(self, level, accuracy, f1, train_count, test_count):
        """Save metrics to SQLite database"""
        import sqlite3
        
        db_path = os.path.join(self.model_dir, "metrics.db")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor = conn.cursor()
        
        metrics_to_save = []
        
        for label, metrics in report_dict.items():
            if isinstance(metrics, dict):
                for metric_name, value in metrics.items():
                    if metric_name in ['precision', 'recall', 'f1-score']:
                        metric_key = f"{label}_{metric_name.replace('-', '_')}"
                        metrics_to_save.append((run_id, task, metric_key, value))
        
        cursor.executemany("""
            INSERT INTO metrics (run_id, task, metric, value)
            VALUES (?, ?, ?, ?)
        """, metrics_to_save)
        
        conn.commit()
        conn.close()
        
        self.logger.info(f"ðŸ’¾ Detailed {task} report saved to database")
    
    def get_latest_metrics_from_db(self):
        """Retrieve latest metrics from database"""
        import sqlite3
        
        db_path = os.path.join(self.model_dir, "metrics.db")
        
        if not os.path.exists(db_path):
            return {"error": "No metrics database found"}
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Get latest run
        cursor.execute("SELECT MAX(run_id) FROM runs")
        latest_run = cursor.fetchone()[0]
        
        if latest_run is None:
            conn.close()
            return {"error": "No training runs found"}
        
        # Get metrics
        cursor.execute("""
            SELECT task, metric, value
            FROM metrics
            WHERE run_id = ?
        """, (latest_run,))
        
        rows = cursor.fetchall()
        conn.close()
        
        return {
            "run_id": latest_run,
            "metrics": [
                {"task": task, "metric": metric, "value": value}
                for task, metric, value in rows
            ]
        }
    
    # ========== DATA EXTRACTION HELPER ==========
    
    def _extract_taxonomy_from_task(self, task):
        """
        CRITICAL FIX: Extract 3-level taxonomy from Label Studio task
        
        Returns: dict with masterdepartment, department, querytype
        """
        result = {
            'masterdepartment': None,
            'department': None,
            'querytype': None,
            'text': None
        }
        
        # Extract text
        if 'data' in task and 'html' in task['data']:
            result['text'] = self.preload_task_data(task, task['data']['html'])
        elif 'data' in task and 'text' in task['data']:
            result['text'] = task['data']['text']
        
        # Extract annotations
        annotations = task.get('annotations', [])
        if not annotations:
            return None
        
        annotation = annotations[0]
        annotation_result = annotation.get('result', [])
        

        #debug

        if len(annotation_result) > 0:
            first_item=annotation_result[0]
            self.logger.debug(f"debug first annotation item :")
            self.logger.debug(f" from_name: {first_item.get('from_name', 'N/A')}")
            self.logger.debug(f" type: {first_item.get('type', 'N/A')}")
            taxonomy_val=first_item.get('value',{}).get('taxonomy',[])
            if taxonomy_val:
                self.logger.debug(f" taxonomy:{taxonomy_val}")

        for item in annotation_result:
            value = item.get('value', {})
            taxonomy = value.get('taxonomy', [[]])
            from_name = item.get('from_name', '').lower()
            
            if not taxonomy or not taxonomy[0]:
                continue
            full_path=taxonomy[0]

            if len(full_path) >= 3:
                result['masterdepartment']=full_path[0]
                result['department']=f"{full_path[0]} > {full_path[1]}"
                result['querytype']=f"{full_path[0]} > {full_path[1]} > {full_path[2]}"
                self.logger.debug(f"Extracted all 3 levels from field '{from_name}'")
                break
            
            elif len(full_path) >=2 and not result['department']:
                result['masterdepartment'] = full_path[0]
                result['department'] = f"{full_path[0]} > {full_path[1]}"
                self.logger.debug(f"Extracted level 2 from field '{from_name}'")
            
            elif len(full_path) >=1 and not result['masterdepartment']:
                result['masterdepartment'] = full_path[0]
                self.logger.debug(f"Extracted level 1 from field '{from_name}'")

        if not result['masterdepartment']:
            self.logger.warning(f"No masterdepartment found in task {task.get('id', 'unknown')}")
            return None
        
        return result
        

        
    
    def fit(self, event, data, tasks, **kwargs):
        """
        3-Level Hierarchical Training Pipeline
        
        Level 1: Email â†’ MasterDepartment
        Level 2: Email + MasterDepartment â†’ Department
        Level 3: Email + MasterDepartment + Department â†’ QueryType
        """
        
        self.logger.info("=" * 80)
        self.logger.info("ðŸš€ 3-LEVEL HIERARCHICAL TRAINING INITIATED")
        self.logger.info("=" * 80)
        
        # Initialize database
        self.init_metrics_db()
        
        # ========== PREPARE DATA ==========
        self.logger.info("ðŸ“Š Preparing training data...")
        
        train_data = []
        for task in tasks:
            extracted = self._extract_taxonomy_from_task(task)
            if extracted and extracted['text']:
                train_data.append(extracted)
        
        if len(train_data) == 0:
            self.logger.error("âŒ No valid training data found")
            self.logger.error("Please check your Label Studio annotations:")
            self.logger.error("  - Ensure tasks have 'masterdepartment' labels")
            self.logger.error("  - Check that taxonomy fields are properly configured")
            return
        
        self.logger.info(f"âœ“ Prepared {len(train_data)} training samples")
        
        # Log sample for debugging
        if train_data:
            sample = train_data[0]
            self.logger.info(f"ðŸ“ Sample annotation:")
            self.logger.info(f"   MasterDepartment: {sample['masterdepartment']}")
            self.logger.info(f"   Department: {sample['department']}")
            self.logger.info(f"   QueryType: {sample['querytype']}")
        
        # Log distribution
        masterdept_count = sum(1 for d in train_data if d['masterdepartment'])
        dept_count = sum(1 for d in train_data if d['department'])
        qt_count = sum(1 for d in train_data if d['querytype'])
        
        self.logger.info(f"ðŸ“Š Label distribution:")
        self.logger.info(f"   Level 1 (MasterDepartment): {masterdept_count} samples")
        self.logger.info(f"   Level 2 (Department): {dept_count} samples")
        self.logger.info(f"   Level 3 (QueryType): {qt_count} samples")
        
        # Convert to DataFrame
        df = pd.DataFrame(train_data)
        
        from sklearn.model_selection import train_test_split
        
        # ========== TRAIN LEVEL 1: MasterDepartment ONLY ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ðŸŽ¯ LEVEL 1 TRAINING: MasterDepartment ONLY")
        self.logger.info("=" * 80)

        # Check if Level 1 model already exists
        level1_model_path = os.path.join(self.model_dir, self.finetuned_model_name)
        level1_classifier_exists = os.path.exists(os.path.join(level1_model_path, 'masterdepartment_classifier.pth'))
        level1_weights_exists = os.path.exists(os.path.join(level1_model_path, 'model.safetensors'))
        level1_encoder_exists = os.path.exists(os.path.join(level1_model_path, 'masterdepartment_encoder.pkl'))

        level1_model_exists = level1_classifier_exists and level1_weights_exists and level1_encoder_exists

        if level1_model_exists:
            self.logger.info("=" * 80)
            self.logger.info("âœ… LEVEL 1 MODEL ALREADY EXISTS - SKIPPING TRAINING")
            self.logger.info("=" * 80)
            self.logger.info(f"ðŸ“ Model path: {level1_model_path}")
            self.logger.info(f"   âœ“ masterdepartment_classifier.pth")
            self.logger.info(f"   âœ“ model.safetensors")
            self.logger.info(f"   âœ“ masterdepartment_encoder.pkl")
            self.logger.info("ðŸ’¡ To retrain Level 1: Delete the masterdepartment_model folder")
            self.logger.info("=" * 80)
        else:
            # Smart split: Keep single-sample classes in training only
            class_counts = df['masterdepartment'].value_counts()
            single_sample_classes = class_counts[class_counts == 1].index.tolist()
            multi_sample_classes = class_counts[class_counts >= 2].index.tolist()

            self.logger.info(f"ðŸ“Š Classes with 1 sample: {len(single_sample_classes)} (will be in training only)")
            self.logger.info(f"ðŸ“Š Classes with 2+ samples: {len(multi_sample_classes)} (will be split)")

            # Separate single-sample data (goes to training only)
            single_sample_df = df[df['masterdepartment'].isin(single_sample_classes)]

            # Separate multi-sample data (will be split)
            multi_sample_df = df[df['masterdepartment'].isin(multi_sample_classes)]

            if len(multi_sample_df) > 0:
                # Split only the multi-sample data
                min_samples = multi_sample_df['masterdepartment'].value_counts().min()
                
                if min_samples >= 2:
                    self.logger.info(f"âœ“ Using stratified split for multi-sample classes")
                    try:
                        level1_train_multi, level1_test_df = train_test_split(
                            multi_sample_df, test_size=0.2, random_state=42,
                            stratify=multi_sample_df['masterdepartment']
                        )
                    except ValueError as e:
                        self.logger.warning(f"âš ï¸  Stratified split failed: {e}")
                        self.logger.warning("âš ï¸  Falling back to random split")
                        level1_train_multi, level1_test_df = train_test_split(
                            multi_sample_df, test_size=0.2, random_state=42
                        )
                else:
                    # Shouldn't happen, but handle it
                    level1_train_multi, level1_test_df = train_test_split(
                        multi_sample_df, test_size=0.2, random_state=42
                    )
                
                # Combine: all single-sample + training portion of multi-sample
                level1_train_df = pd.concat([single_sample_df, level1_train_multi], ignore_index=True)
            else:
                # All classes have only 1 sample
                level1_train_df = single_sample_df
                level1_test_df = pd.DataFrame(columns=df.columns)  # Empty test set
                self.logger.warning("âš ï¸  All classes have only 1 sample - no test set will be created")

            self.logger.info(f"ðŸ“Š Level 1 - Train: {len(level1_train_df)} | Test: {len(level1_test_df)}")
            self._train_level1(level1_train_df, level1_test_df)

        
        # ========== TRAIN LEVEL 2: Department ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ðŸŽ¯ LEVEL 2 TRAINING: Department")
        self.logger.info("=" * 80)

        # Filter samples with department labels FIRST
        dept_df = df[df['department'].notna()].copy()

        if len(dept_df) > 0:
            self.logger.info(f"ðŸ“Š Department samples: {len(dept_df)}")
            
            # Smart split: Keep single-sample classes in training only
            dept_class_counts = dept_df['department'].value_counts()
            dept_single_sample_classes = dept_class_counts[dept_class_counts == 1].index.tolist()
            dept_multi_sample_classes = dept_class_counts[dept_class_counts >= 2].index.tolist()
            
            self.logger.info(f"ðŸ“Š Departments with 1 sample: {len(dept_single_sample_classes)} (will be in training only)")
            self.logger.info(f"ðŸ“Š Departments with 2+ samples: {len(dept_multi_sample_classes)} (will be split)")
            
            # Separate single-sample data
            dept_single_sample_df = dept_df[dept_df['department'].isin(dept_single_sample_classes)]
            
            # Separate multi-sample data
            dept_multi_sample_df = dept_df[dept_df['department'].isin(dept_multi_sample_classes)]
            
            if len(dept_multi_sample_df) > 0:
                # Split only the multi-sample data
                dept_min_samples = dept_multi_sample_df['department'].value_counts().min()
                
                if dept_min_samples >= 2:
                    self.logger.info(f"âœ“ Using stratified split for departments")
                    try:
                        dept_train_multi, dept_test_df = train_test_split(
                            dept_multi_sample_df, test_size=0.2, random_state=42,
                            stratify=dept_multi_sample_df['department']
                        )
                    except ValueError as e:
                        self.logger.warning(f"âš ï¸  Stratified split failed: {e}")
                        self.logger.warning("âš ï¸  Falling back to random split")
                        dept_train_multi, dept_test_df = train_test_split(
                            dept_multi_sample_df, test_size=0.2, random_state=42
                        )
                else:
                    dept_train_multi, dept_test_df = train_test_split(
                        dept_multi_sample_df, test_size=0.2, random_state=42
                    )
                
                # Combine: all single-sample + training portion of multi-sample
                dept_train_df = pd.concat([dept_single_sample_df, dept_train_multi], ignore_index=True)
            else:
                # All departments have only 1 sample
                dept_train_df = dept_single_sample_df
                dept_test_df = pd.DataFrame(columns=dept_df.columns)
                self.logger.warning("âš ï¸  All departments have only 1 sample - no test set will be created")
            
            self.logger.info(f"ðŸ“Š Level 2 - Train: {len(dept_train_df)} | Test: {len(dept_test_df)}")
            self._train_level2(dept_train_df, dept_test_df)
        else:
            self.logger.warning("âš ï¸  No Department labels found - skipping Level 2 training")
        
        # ========== TRAIN LEVEL 3: QueryType ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info("ðŸŽ¯ LEVEL 3 TRAINING: QueryType")
        self.logger.info("=" * 80)

        # Filter samples with querytype labels FIRST
        qt_df = df[df['querytype'].notna()].copy()

        if len(qt_df) > 0:
            self.logger.info(f"ðŸ“Š QueryType samples: {len(qt_df)}")
            
            # Smart split: Keep single-sample classes in training only
            qt_class_counts = qt_df['querytype'].value_counts()
            qt_single_sample_classes = qt_class_counts[qt_class_counts == 1].index.tolist()
            qt_multi_sample_classes = qt_class_counts[qt_class_counts >= 2].index.tolist()
            
            self.logger.info(f"ðŸ“Š QueryTypes with 1 sample: {len(qt_single_sample_classes)} (will be in training only)")
            self.logger.info(f"ðŸ“Š QueryTypes with 2+ samples: {len(qt_multi_sample_classes)} (will be split)")
            
            # Separate single-sample data
            qt_single_sample_df = qt_df[qt_df['querytype'].isin(qt_single_sample_classes)]
            
            # Separate multi-sample data
            qt_multi_sample_df = qt_df[qt_df['querytype'].isin(qt_multi_sample_classes)]
            
            if len(qt_multi_sample_df) > 0:
                # Split only the multi-sample data
                qt_min_samples = qt_multi_sample_df['querytype'].value_counts().min()
                
                if qt_min_samples >= 2:
                    self.logger.info(f"âœ“ Using stratified split for querytypes")
                    try:
                        qt_train_multi, qt_test_df = train_test_split(
                            qt_multi_sample_df, test_size=0.2, random_state=42,
                            stratify=qt_multi_sample_df['querytype']
                        )
                    except ValueError as e:
                        self.logger.warning(f"âš ï¸  Stratified split failed: {e}")
                        self.logger.warning("âš ï¸  Falling back to random split")
                        qt_train_multi, qt_test_df = train_test_split(
                            qt_multi_sample_df, test_size=0.2, random_state=42
                        )
                else:
                    qt_train_multi, qt_test_df = train_test_split(
                        qt_multi_sample_df, test_size=0.2, random_state=42
                    )
                
                # Combine: all single-sample + training portion of multi-sample
                qt_train_df = pd.concat([qt_single_sample_df, qt_train_multi], ignore_index=True)
            else:
                # All querytypes have only 1 sample
                qt_train_df = qt_single_sample_df
                qt_test_df = pd.DataFrame(columns=qt_df.columns)
                self.logger.warning("âš ï¸  All querytypes have only 1 sample - no test set will be created")
            
            self.logger.info(f"ðŸ“Š Level 3 - Train: {len(qt_train_df)} | Test: {len(qt_test_df)}")
            self._train_level3(qt_train_df, qt_test_df)
        else:
            self.logger.warning("âš ï¸  No QueryType labels found - skipping Level 3 training")
    
    def _train_level1(self, train_df, test_df):
        """Train Level 1: MasterDepartment ONLY"""
        
        from sklearn.preprocessing import LabelEncoder
        from sklearn.utils import compute_class_weight
        from transformers import get_cosine_schedule_with_warmup
        
        # Encode labels
        masterdept_encoder = LabelEncoder()
        
        train_masterdept_encoded = masterdept_encoder.fit_transform(train_df['masterdepartment'])
        test_masterdept_encoded  = masterdept_encoder.transform(test_df['masterdepartment'])
        
        self.logger.info(f"ðŸ“Š MasterDepartment classes: {len(masterdept_encoder.classes_)}")
        
        # Initialize model
        num_masterdept = len(masterdept_encoder.classes_)
        device = self._get_device()
        
        model = MasterDepartmentModel(
            self.baseline_model_name,
            num_labels=num_masterdept
        )
        model.to(device)
        
        # Tokenize
        tokenizer = self.tokenizer
        MAX_LEN = 256
        
        train_inputs, train_masks = self._tokenize_and_pad(train_df['text'].tolist(), tokenizer, MAX_LEN)
        test_inputs,  test_masks  = self._tokenize_and_pad(test_df['text'].tolist(),  tokenizer, MAX_LEN)
        
        # Create DataLoaders
        train_dataloader = self._create_dataloader(
            train_inputs, train_masks,
            labels=train_masterdept_encoded,
            batch_size=16,
            shuffle=True
        )
        
        # â”€â”€ Training setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        NUM_EPOCHS    = int(os.getenv('L1_TRAIN_EPOCHS', 5))
        LEARNING_RATE = float(os.getenv('LEARNING_RATE', 2e-5))
        
        # Class weights (balanced, capped at 10x) â€” forces model to learn rare classes
        raw_weights = compute_class_weight(
            class_weight='balanced',
            classes=np.unique(train_masterdept_encoded),
            y=train_masterdept_encoded
        )
        raw_weights  = np.clip(raw_weights, 0.1, 10.0)
        class_weights_tensor = torch.tensor(raw_weights, dtype=torch.float32).to(device)
        self.logger.info(f"âš–ï¸  L1 class weights â€” min: {raw_weights.min():.3f}  max: {raw_weights.max():.3f}  "
                         f"classes at 10x cap: {(raw_weights >= 9.99).sum()}")
        
        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
        
        # LR warmup (100 steps) + cosine decay
        total_steps   = len(train_dataloader) * NUM_EPOCHS
        warmup_steps  = min(100, total_steps // 10)
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=total_steps
        )
        self.logger.info(f"ðŸ“… L1 â€” epochs: {NUM_EPOCHS} | warmup steps: {warmup_steps} | total steps: {total_steps}")
        
        # Checkpoint directory â€” one complete model saved per epoch
        checkpoint_dir = os.path.join(self.model_dir, "masterdepartment_model_checkpoints")
        os.makedirs(checkpoint_dir, exist_ok=True)
        self.logger.info(f"ðŸ“‚ Per-epoch checkpoints â†’ {checkpoint_dir}")
        
        # Training logger
        training_logger = TrainingLogger(self.logger, NUM_EPOCHS, len(train_dataloader))
        training_logger.start_training("Level 1 (MasterDepartment)")
        
        # â”€â”€ Training loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for epoch in range(NUM_EPOCHS):
            training_logger.start_epoch(epoch)
            
            model.train()
            total_loss = 0
            
            for batch_idx, batch in enumerate(train_dataloader):
                input_ids, attention_mask, labels_batch = [t.to(device) for t in batch]
                
                optimizer.zero_grad()
                logits = model(input_ids, attention_mask)
                loss   = criterion(logits, labels_batch)
                loss.backward()
                
                # Gradient clipping â€” prevents instability from high class weights
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                scheduler.step()
                
                total_loss += loss.item()
                training_logger.log_batch(epoch, batch_idx, loss.item())
            
            avg_loss = total_loss / len(train_dataloader)
            training_logger.end_epoch(epoch, avg_loss)
            
            # â”€â”€ Per-epoch evaluation on test set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            model.eval()
            epoch_preds = []
            with torch.no_grad():
                eval_dl = self._create_dataloader(test_inputs, test_masks, batch_size=16, shuffle=False)
                for batch in eval_dl:
                    ids, masks = [t.to(device) for t in batch]
                    epoch_preds.extend(torch.argmax(model(ids, masks), dim=1).cpu().numpy())
            
            from sklearn.metrics import f1_score as _f1
            ep_acc    = accuracy_score(test_masterdept_encoded, epoch_preds)
            ep_macro  = _f1(test_masterdept_encoded, epoch_preds, average='macro',    zero_division=0)
            ep_weighted = _f1(test_masterdept_encoded, epoch_preds, average='weighted', zero_division=0)
            
            self.logger.info(
                f"ðŸ“Š [L1 Epoch {epoch+1}/{NUM_EPOCHS}] "
                f"Loss: {avg_loss:.4f} | Acc: {ep_acc:.4f} | "
                f"Macro-F1: {ep_macro:.4f} | Weighted-F1: {ep_weighted:.4f}  â† use Macro-F1 to pick best epoch"
            )
            
            # â”€â”€ Save complete checkpoint after every epoch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            epoch_ckpt_dir = os.path.join(checkpoint_dir, f"epoch_{epoch+1}")
            model.set_encoder(masterdept_encoder)
            model.save(epoch_ckpt_dir)
            tokenizer.save_pretrained(epoch_ckpt_dir)
            self.logger.info(f"ðŸ’¾ L1 Epoch {epoch+1} checkpoint saved â†’ {epoch_ckpt_dir}")
        
        training_logger.end_training()
        
        # â”€â”€ Final evaluation (last epoch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.logger.info("")
        self.logger.info("ðŸ“Š Evaluating Level 1 model...")
        
        model.eval()
        test_dataloader = self._create_dataloader(test_inputs, test_masks, batch_size=16, shuffle=False)
        
        masterdept_preds = []
        with torch.no_grad():
            for batch in test_dataloader:
                input_ids, attention_mask = [t.to(device) for t in batch]
                logits = model(input_ids, attention_mask)
                masterdept_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())
        
        masterdept_accuracy = accuracy_score(test_masterdept_encoded, masterdept_preds)
        masterdept_f1       = f1_score(test_masterdept_encoded, masterdept_preds, average='weighted', zero_division=0)
        
        self.logger.info(f"âœ… MasterDepartment - Accuracy: {masterdept_accuracy:.4f} | F1: {masterdept_f1:.4f}")
        self.logger.info(f"ðŸ’¡ TIP: Check per-epoch Macro-F1 above â€” load the best epoch from {checkpoint_dir}")
        
        # Save final model
        model.set_encoder(masterdept_encoder)
        save_path = os.path.join(self.model_dir, self.finetuned_model_name)
        model.save(save_path)
        tokenizer.save_pretrained(save_path)
        self.logger.info(f"ðŸ’¾ Level 1 model saved to {save_path}")
        
        # Save metrics to DB
        decoded_masterdept_true = masterdept_encoder.inverse_transform(test_masterdept_encoded)
        decoded_masterdept_pred = masterdept_encoder.inverse_transform(masterdept_preds)
        
        run_id = self.save_metrics_to_sqlite(
            1, masterdept_accuracy, masterdept_f1,
            len(train_df), len(test_df)
        )
        self.save_full_classification_report_to_sqlite(run_id, "masterdepartment", decoded_masterdept_true, decoded_masterdept_pred)
    
    def _train_level2(self, train_df, test_df):
        """Train Level 2: Department (conditioned on MasterDepartment)"""
        
        from sklearn.preprocessing import LabelEncoder
        from sklearn.utils import compute_class_weight
        from transformers import get_cosine_schedule_with_warmup
        
        # Encode labels
        dept_encoder = LabelEncoder()
        
        train_dept_encoded = dept_encoder.fit_transform(train_df['department'])
        test_dept_encoded  = dept_encoder.transform(test_df['department'])
        
        self.logger.info(f"ðŸ“Š Department classes: {len(dept_encoder.classes_)}")
        
        # Initialize model
        num_departments = len(dept_encoder.classes_)
        device = self._get_device()
        
        model = DepartmentNNModel(
            self.baseline_model_name,
            num_labels=num_departments
        )
        model.to(device)
        
        # Prepare conditional input: "MasterDepartment: X Email: Y"
        train_texts_conditional = [
            f"MasterDepartment: {row['masterdepartment']} Email: {row['text']}"
            for _, row in train_df.iterrows()
        ]
        
        test_texts_conditional = [
            f"MasterDepartment: {row['masterdepartment']} Email: {row['text']}"
            for _, row in test_df.iterrows()
        ]
        
        # Tokenize
        tokenizer = self.tokenizer
        MAX_LEN = 256
        
        train_inputs, train_masks = self._tokenize_and_pad(train_texts_conditional, tokenizer, MAX_LEN)
        test_inputs,  test_masks  = self._tokenize_and_pad(test_texts_conditional,  tokenizer, MAX_LEN)
        
        # Create DataLoaders
        train_dataloader = self._create_dataloader(
            train_inputs, train_masks,
            labels=train_dept_encoded,
            batch_size=16,
            shuffle=True
        )
        
        # â”€â”€ Training setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        NUM_EPOCHS    = int(os.getenv('L2_TRAIN_EPOCHS', 6))
        LEARNING_RATE = float(os.getenv('LEARNING_RATE', 2e-5))
        
        # Class weights (balanced, capped at 10x) â€” critical for departments with few samples
        raw_weights = compute_class_weight(
            class_weight='balanced',
            classes=np.unique(train_dept_encoded),
            y=train_dept_encoded
        )
        raw_weights  = np.clip(raw_weights, 0.1, 10.0)
        class_weights_tensor = torch.tensor(raw_weights, dtype=torch.float32).to(device)
        self.logger.info(f"âš–ï¸  L2 class weights â€” min: {raw_weights.min():.3f}  max: {raw_weights.max():.3f}  "
                         f"classes at 10x cap: {(raw_weights >= 9.99).sum()}")
        
        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
        
        # LR warmup (200 steps) + cosine decay
        total_steps  = len(train_dataloader) * NUM_EPOCHS
        warmup_steps = min(200, total_steps // 10)
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=total_steps
        )
        self.logger.info(f"ðŸ“… L2 â€” epochs: {NUM_EPOCHS} | warmup steps: {warmup_steps} | total steps: {total_steps}")
        
        # Checkpoint directory â€” one complete model saved per epoch
        checkpoint_dir = os.path.join(self.model_dir, "department_model_checkpoints")
        os.makedirs(checkpoint_dir, exist_ok=True)
        self.logger.info(f"ðŸ“‚ Per-epoch checkpoints â†’ {checkpoint_dir}")
        
        # Training logger
        training_logger = TrainingLogger(self.logger, NUM_EPOCHS, len(train_dataloader))
        training_logger.start_training("Level 2 (Department)")
        
        # â”€â”€ Training loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for epoch in range(NUM_EPOCHS):
            training_logger.start_epoch(epoch)
            
            model.train()
            total_loss = 0
            
            for batch_idx, batch in enumerate(train_dataloader):
                input_ids, attention_mask, labels_batch = [t.to(device) for t in batch]
                
                optimizer.zero_grad()
                logits = model(input_ids, attention_mask)
                loss   = criterion(logits, labels_batch)
                loss.backward()
                
                # Gradient clipping â€” prevents instability from high class weights
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                scheduler.step()
                
                total_loss += loss.item()
                training_logger.log_batch(epoch, batch_idx, loss.item())
            
            avg_loss = total_loss / len(train_dataloader)
            training_logger.end_epoch(epoch, avg_loss)
            
            # â”€â”€ Per-epoch evaluation on test set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            model.eval()
            epoch_preds = []
            with torch.no_grad():
                eval_dl = self._create_dataloader(test_inputs, test_masks, batch_size=16, shuffle=False)
                for batch in eval_dl:
                    ids, masks = [t.to(device) for t in batch]
                    epoch_preds.extend(torch.argmax(model(ids, masks), dim=1).cpu().numpy())
            
            from sklearn.metrics import f1_score as _f1
            ep_acc      = accuracy_score(test_dept_encoded, epoch_preds)
            ep_macro    = _f1(test_dept_encoded, epoch_preds, average='macro',    zero_division=0)
            ep_weighted = _f1(test_dept_encoded, epoch_preds, average='weighted', zero_division=0)
            
            self.logger.info(
                f"ðŸ“Š [L2 Epoch {epoch+1}/{NUM_EPOCHS}] "
                f"Loss: {avg_loss:.4f} | Acc: {ep_acc:.4f} | "
                f"Macro-F1: {ep_macro:.4f} | Weighted-F1: {ep_weighted:.4f}  â† use Macro-F1 to pick best epoch"
            )
            
            # â”€â”€ Save complete checkpoint after every epoch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            epoch_ckpt_dir = os.path.join(checkpoint_dir, f"epoch_{epoch+1}")
            model.set_encoder(dept_encoder)
            model.save(epoch_ckpt_dir)
            self.logger.info(f"ðŸ’¾ L2 Epoch {epoch+1} checkpoint saved â†’ {epoch_ckpt_dir}")
        
        training_logger.end_training()
        
        # â”€â”€ Final evaluation (last epoch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.logger.info("")
        self.logger.info("ðŸ“Š Evaluating Level 2 model...")
        
        model.eval()
        test_dataloader = self._create_dataloader(test_inputs, test_masks, batch_size=16, shuffle=False)
        
        dept_preds = []
        with torch.no_grad():
            for batch in test_dataloader:
                input_ids, attention_mask = [t.to(device) for t in batch]
                logits = model(input_ids, attention_mask)
                dept_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())
        
        dept_accuracy = accuracy_score(test_dept_encoded, dept_preds)
        dept_f1       = f1_score(test_dept_encoded, dept_preds, average='weighted', zero_division=0)
        
        self.logger.info(f"âœ… Department - Accuracy: {dept_accuracy:.4f} | F1: {dept_f1:.4f}")
        self.logger.info(f"ðŸ’¡ TIP: Check per-epoch Macro-F1 above â€” load the best epoch from {checkpoint_dir}")
        
        # Save final model
        model.set_encoder(dept_encoder)
        save_path = os.path.join(self.model_dir, "department_model")
        model.save(save_path)
        self.logger.info(f"ðŸ’¾ Level 2 model saved to {save_path}")
        
        # Save metrics to DB
        decoded_dept_true = dept_encoder.inverse_transform(test_dept_encoded)
        decoded_dept_pred = dept_encoder.inverse_transform(dept_preds)
        
        run_id = self.save_metrics_to_sqlite(
            2, dept_accuracy, dept_f1,
            len(train_df), len(test_df)
        )
        self.save_full_classification_report_to_sqlite(run_id, "department", decoded_dept_true, decoded_dept_pred)
    
    def _train_level3(self, train_df, test_df):
        """Train Level 3: QueryType (conditioned on MasterDepartment + Department)"""
        
        from sklearn.preprocessing import LabelEncoder
        from sklearn.utils import compute_class_weight
        from transformers import get_cosine_schedule_with_warmup
        
        # Encode labels
        qt_encoder = LabelEncoder()
        
        train_qt_encoded = qt_encoder.fit_transform(train_df['querytype'])
        test_qt_encoded  = qt_encoder.transform(test_df['querytype'])
        
        self.logger.info(f"ðŸ“Š QueryType classes: {len(qt_encoder.classes_)}")
        
        # Initialize model
        num_querytypes = len(qt_encoder.classes_)
        device = self._get_device()
        
        model = QueryTypeNNModel(
            self.baseline_model_name,
            num_labels=num_querytypes
        )
        model.to(device)
        
        # Prepare conditional input: "MasterDepartment: X Department: Y Email: Z"
        train_texts_conditional = [
            f"MasterDepartment: {row['masterdepartment']} Department: {row['department']} Email: {row['text']}"
            for _, row in train_df.iterrows()
        ]
        
        test_texts_conditional = [
            f"MasterDepartment: {row['masterdepartment']} Department: {row['department']} Email: {row['text']}"
            for _, row in test_df.iterrows()
        ]
        
        # Tokenize
        tokenizer = self.tokenizer
        MAX_LEN = 256
        
        train_inputs, train_masks = self._tokenize_and_pad(train_texts_conditional, tokenizer, MAX_LEN)
        test_inputs,  test_masks  = self._tokenize_and_pad(test_texts_conditional,  tokenizer, MAX_LEN)
        
        # Create DataLoaders
        train_dataloader = self._create_dataloader(
            train_inputs, train_masks,
            labels=train_qt_encoded,
            batch_size=16,
            shuffle=True
        )
        
        # â”€â”€ Training setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        NUM_EPOCHS    = int(os.getenv('L3_TRAIN_EPOCHS', 8))
        LEARNING_RATE = float(os.getenv('LEARNING_RATE', 2e-5))
        
        # Class weights (balanced, capped at 10x) â€” most important for L3
        # 148 classes with 62 having <10 samples â€” without weights model ignores them completely
        raw_weights = compute_class_weight(
            class_weight='balanced',
            classes=np.unique(train_qt_encoded),
            y=train_qt_encoded
        )
        raw_weights  = np.clip(raw_weights, 0.1, 10.0)
        class_weights_tensor = torch.tensor(raw_weights, dtype=torch.float32).to(device)
        self.logger.info(f"âš–ï¸  L3 class weights â€” min: {raw_weights.min():.3f}  max: {raw_weights.max():.3f}  "
                         f"classes at 10x cap: {(raw_weights >= 9.99).sum()}")
        
        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
        
        # LR warmup (500 steps) + cosine decay
        # L3 needs longer warmup â€” 148 classes, many rare, model needs stable early learning
        total_steps  = len(train_dataloader) * NUM_EPOCHS
        warmup_steps = min(500, total_steps // 10)
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=total_steps
        )
        self.logger.info(f"ðŸ“… L3 â€” epochs: {NUM_EPOCHS} | warmup steps: {warmup_steps} | total steps: {total_steps}")
        
        # Checkpoint directory â€” one complete model saved per epoch
        checkpoint_dir = os.path.join(self.model_dir, "querytype_model_checkpoints")
        os.makedirs(checkpoint_dir, exist_ok=True)
        self.logger.info(f"ðŸ“‚ Per-epoch checkpoints â†’ {checkpoint_dir}")
        
        # Training logger
        training_logger = TrainingLogger(self.logger, NUM_EPOCHS, len(train_dataloader))
        training_logger.start_training("Level 3 (QueryType)")
        
        # â”€â”€ Training loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for epoch in range(NUM_EPOCHS):
            training_logger.start_epoch(epoch)
            
            model.train()
            total_loss = 0
            
            for batch_idx, batch in enumerate(train_dataloader):
                input_ids, attention_mask, labels_batch = [t.to(device) for t in batch]
                
                optimizer.zero_grad()
                logits = model(input_ids, attention_mask)
                loss   = criterion(logits, labels_batch)
                loss.backward()
                
                # Gradient clipping â€” prevents instability from high class weights
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                scheduler.step()
                
                total_loss += loss.item()
                training_logger.log_batch(epoch, batch_idx, loss.item())
            
            avg_loss = total_loss / len(train_dataloader)
            training_logger.end_epoch(epoch, avg_loss)
            
            # â”€â”€ Per-epoch evaluation on test set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            model.eval()
            epoch_preds = []
            with torch.no_grad():
                eval_dl = self._create_dataloader(test_inputs, test_masks, batch_size=16, shuffle=False)
                for batch in eval_dl:
                    ids, masks = [t.to(device) for t in batch]
                    epoch_preds.extend(torch.argmax(model(ids, masks), dim=1).cpu().numpy())
            
            from sklearn.metrics import f1_score as _f1
            ep_acc      = accuracy_score(test_qt_encoded, epoch_preds)
            ep_macro    = _f1(test_qt_encoded, epoch_preds, average='macro',    zero_division=0)
            ep_weighted = _f1(test_qt_encoded, epoch_preds, average='weighted', zero_division=0)
            
            self.logger.info(
                f"ðŸ“Š [L3 Epoch {epoch+1}/{NUM_EPOCHS}] "
                f"Loss: {avg_loss:.4f} | Acc: {ep_acc:.4f} | "
                f"Macro-F1: {ep_macro:.4f} | Weighted-F1: {ep_weighted:.4f}  â† use Macro-F1 to pick best epoch"
            )
            
            # â”€â”€ Save complete checkpoint after every epoch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            epoch_ckpt_dir = os.path.join(checkpoint_dir, f"epoch_{epoch+1}")
            model.set_encoder(qt_encoder)
            model.save(epoch_ckpt_dir)
            self.logger.info(f"ðŸ’¾ L3 Epoch {epoch+1} checkpoint saved â†’ {epoch_ckpt_dir}")
        
        training_logger.end_training()
        
        # â”€â”€ Final evaluation (last epoch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.logger.info("")
        self.logger.info("ðŸ“Š Evaluating Level 3 model...")
        
        model.eval()
        test_dataloader = self._create_dataloader(test_inputs, test_masks, batch_size=16, shuffle=False)
        
        qt_preds = []
        with torch.no_grad():
            for batch in test_dataloader:
                input_ids, attention_mask = [t.to(device) for t in batch]
                logits = model(input_ids, attention_mask)
                qt_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())
        
        qt_accuracy = accuracy_score(test_qt_encoded, qt_preds)
        qt_f1       = f1_score(test_qt_encoded, qt_preds, average='weighted', zero_division=0)
        
        self.logger.info(f"âœ… QueryType - Accuracy: {qt_accuracy:.4f} | F1: {qt_f1:.4f}")
        self.logger.info(f"ðŸ’¡ TIP: Check per-epoch Macro-F1 above â€” load the best epoch from {checkpoint_dir}")
        
        # Save final model
        model.set_encoder(qt_encoder)
        save_path = os.path.join(self.model_dir, "querytype_model")
        model.save(save_path)
        self.logger.info(f"ðŸ’¾ Level 3 model saved to {save_path}")
        
        # Save metrics to DB
        decoded_qt_true = qt_encoder.inverse_transform(test_qt_encoded)
        decoded_qt_pred = qt_encoder.inverse_transform(qt_preds)
        
        run_id = self.save_metrics_to_sqlite(
            3, qt_accuracy, qt_f1,
            len(train_df), len(test_df)
        )
        self.save_full_classification_report_to_sqlite(run_id, "querytype", decoded_qt_true, decoded_qt_pred)

    def fit_external(self, event, data, tasks, **kwargs):
        """External training wrapper"""
        self.logger.info("ðŸš€ External training initiated")
        return self.fit(event, data, tasks, **kwargs)

    def predict(self, tasks: List[Dict], texts: str, context: Optional[Dict] = None, **kwargs):
        """
        3-LEVEL HIERARCHICAL INFERENCE PIPELINE
        
        Just pass email text, automatically routes through:
        1. Level 1: Email â†’ MasterDepartment
        2. Level 2: Email + MasterDepartment â†’ Department
        3. Level 3: Email + MasterDepartment + Department â†’ QueryType
        
        Returns all predictions in a single result.
        """
        
        try:
            self.logger.info("=" * 80)
            self.logger.info("ðŸ” PREDICTION REQUEST RECEIVED")
            self.logger.info("=" * 80)
            
            # ========== VALIDATION ==========
            if self.model is None:
                error_msg = "âŒ Level 1 model not loaded - cannot make predictions"
                self.logger.error(error_msg)
                return []
            
            if self.tokenizer is None:
                error_msg = "âŒ Tokenizer not loaded - cannot make predictions"
                self.logger.error(error_msg)
                return []
            
            # NOTE: label_interface is optional - only needed for Label Studio mode
            
            self.logger.info("âœ“ All required components loaded")

            # ========== GET LABEL STUDIO TAGS (Optional for external calls) ==========
            try:
                if self.label_interface is not None:
                    # Label Studio mode - get proper tags
                    def getMasterDepartmentAttrName(attrs):
                        return attrs == "masterdepartment"

                    def getDepartmentAttrName(attrs):
                        return attrs == "department"

                    def getQueryTypeAttrName(attrs):
                        return attrs == "querytype"

                    from_name_masterdepartment, to_name_masterdepartment, _ = \
                        self.label_interface.get_first_tag_occurence(
                            'Taxonomy', 'HyperText', getMasterDepartmentAttrName
                        )

                    from_name_department, to_name_department, _ = \
                        self.label_interface.get_first_tag_occurence(
                            "Taxonomy", "HyperText", getDepartmentAttrName
                        )

                    from_name_querytype, to_name_querytype, _ = \
                        self.label_interface.get_first_tag_occurence(
                            "Taxonomy", "HyperText", getQueryTypeAttrName
                        )
                    
                    self.logger.info("âœ“ Label Studio tags retrieved successfully")
                else:
                    # External API mode - use default tags
                    from_name_masterdepartment = "masterdepartment"
                    to_name_masterdepartment = "text"
                    from_name_department = "department"
                    to_name_department = "text"
                    from_name_querytype = "querytype"
                    to_name_querytype = "text"
                    
                    self.logger.info("âœ“ Using default tags (external API mode)")
                
            except Exception as e:
                self.logger.error(f"âŒ Error getting tags: {e}")
                # Use defaults as fallback
                from_name_masterdepartment = "masterdepartment"
                to_name_masterdepartment = "text"
                from_name_department = "department"
                to_name_department = "text"
                from_name_querytype = "querytype"
                to_name_querytype = "text"
                self.logger.info("âœ“ Using fallback default tags")

            # ========== EXTRACT TEXT FROM INPUT ==========
            try:
                self.logger.info(f"ðŸ“ Input type: {type(texts)}")
                self.logger.info(f"ðŸ“ Input length: {len(texts) if isinstance(texts, (list, str)) else 'N/A'}")
                
                text_list = []
                
                if isinstance(texts, str):
                    # Single string
                    text_list = [texts]
                    self.logger.info("âœ“ Processing single string input")
                    
                elif isinstance(texts, list):
                    # List of texts or dicts
                    for idx, text in enumerate(texts):
                        if isinstance(text, dict):
                            if 'text' in text:
                                text_list.append(text['text'])
                            elif 'html' in text:
                                text_list.append(text['html'])
                            else:
                                text_list.append(str(text))
                        elif isinstance(text, str):
                            text_list.append(text)
                        else:
                            text_list.append(str(text))
                    
                    self.logger.info(f"âœ“ Processing list with {len(text_list)} items")
                    
                elif isinstance(texts, dict):
                    # Single dict
                    if 'text' in texts:
                        text_list = [texts['text']]
                    elif 'html' in texts:
                        text_list = [texts['html']]
                    else:
                        text_list = [str(texts)]
                    
                    self.logger.info("âœ“ Processing single dict input")
                    
                else:
                    # Fallback
                    text_list = [str(texts)]
                    self.logger.warning(f"âš ï¸  Unknown input type, converting to string")
                
                if not text_list or all(not t for t in text_list):
                    error_msg = "âŒ No valid text found in input"
                    self.logger.error(error_msg)
                    return []
                
                self.logger.info(f"ðŸ“Š Successfully extracted {len(text_list)} text(s) for processing")
                
                # Log first text sample for debugging
                if text_list:
                    sample_text = text_list[0][:100] + "..." if len(text_list[0]) > 100 else text_list[0]
                    self.logger.info(f"ðŸ“„ Sample text: {sample_text}")
                
            except Exception as e:
                self.logger.error(f"âŒ Error extracting text from input: {e}")
                self.logger.exception("Full traceback:")
                return []

            # ========== TOKENIZATION ==========
            try:
                tokenizer = self.tokenizer
                MAX_LEN = 256
                batch_size = 16

                self.logger.info(f"ðŸ”¤ Tokenizing {len(text_list)} text(s)...")
                
                # Tokenize and pad
                _inputs, _masks = self._tokenize_and_pad(text_list, tokenizer, MAX_LEN)
                
                self.logger.info(f"âœ“ Tokenization complete - Shape: {_inputs.shape}")

                # Create DataLoader
                dataloader = self._create_dataloader(
                    _inputs, _masks, batch_size=batch_size, shuffle=False
                )
                
                self.logger.info(f"âœ“ DataLoader created - {len(dataloader)} batches")
                
            except Exception as e:
                self.logger.error(f"âŒ Error during tokenization: {e}")
                self.logger.exception("Full traceback:")
                return []

            # ========== SETUP MODELS ==========
            try:
                device = self._get_device()
                self.logger.info(f"ðŸ–¥ï¸  Using device: {device}")
                
                # Move models to device and set to eval mode
                self.model.to(device)
                self.model.eval()
                self.logger.info("âœ“ Level 1 model ready")

                if self.department_model is not None:
                    self.department_model.to(device)
                    self.department_model.eval()
                    self.logger.info("âœ“ Level 2 model ready - Department predictions enabled")
                else:
                    self.logger.info("âš ï¸  Level 2 model not loaded - Department predictions will be skipped")

                if self.querytype_model is not None:
                    self.querytype_model.to(device)
                    self.querytype_model.eval()
                    self.logger.info("âœ“ Level 3 model ready - QueryType predictions enabled")
                else:
                    self.logger.info("âš ï¸  Level 3 model not loaded - QueryType predictions will be skipped")
                    
            except Exception as e:
                self.logger.error(f"âŒ Error setting up models: {e}")
                self.logger.exception("Full traceback:")
                return []

            # ========== RUN INFERENCE ==========
            try:
                self.logger.info("ðŸš€ Starting inference...")
                
                predictions = []
                global_text_idx = 0

                with torch.no_grad():
                    for batch_idx, batch in enumerate(dataloader):
                        self.logger.info(f"   Processing batch {batch_idx + 1}/{len(dataloader)}...")
                        
                        input_ids, attention_mask = [t.to(device) for t in batch]
            
                        # ========== LEVEL 1: MasterDepartment ==========
                        try:
                            masterdept_logits = self.model(input_ids, attention_mask)
                            masterdept_probs = torch.softmax(masterdept_logits, dim=1)
                            masterdept_preds = torch.argmax(masterdept_probs, dim=1)

                            decoded_masterdept_preds = self._decode_predictions(
                                masterdept_preds, 'masterdepartment'
                            )
                            
                            self.logger.info(f"   âœ“ Level 1 predictions: {decoded_masterdept_preds}")
                            
                        except Exception as e:
                            self.logger.error(f"âŒ Error in Level 1 prediction: {e}")
                            self.logger.exception("Full traceback:")
                            raise

                        for i in range(len(masterdept_preds)):
                            try:
                                current_text = text_list[global_text_idx]
                                global_text_idx += 1

                                # ---------- MASTER DEPARTMENT ----------
                                predictions.append({
                                    "from_name": from_name_masterdepartment,
                                    "to_name": to_name_masterdepartment,
                                    "type": "taxonomy",
                                    "value": {
                                        "taxonomy": [
                                            [decoded_masterdept_preds[i]]
                                        ],
                                        "score": float(masterdept_probs[i][masterdept_preds[i]].item())
                                    }
                                })

                                # ========== LEVEL 2: DEPARTMENT ==========
                                if self.department_model is not None:
                                    try:
                                        conditional_text = (
                                            f"MasterDepartment: {decoded_masterdept_preds[i]} "
                                            f"Email: {current_text}"
                                        )

                                        dept_ids = tokenizer.encode(
                                            conditional_text,
                                            add_special_tokens=True,
                                            max_length=256,
                                            truncation=True
                                        )
                                        dept_mask = [int(t > 0) for t in dept_ids]

                                        dept_logits = self.department_model(
                                            torch.tensor([dept_ids]).to(device),
                                            torch.tensor([dept_mask]).to(device)
                                        )

                                        if isinstance(dept_logits, (tuple, list)):
                                            dept_logits = dept_logits[0]

                                        dept_probs = torch.softmax(dept_logits, dim=1)
                                        
                                        # ========== HIERARCHICAL CONSTRAINT FOR LEVEL 2 ==========
                                        dept_encoder = self.department_model.get_encoder()
                                        all_departments = dept_encoder.classes_
                                        
                                        current_masterdept = decoded_masterdept_preds[i]
                                        
                                        # Filter to only Departments that start with current MasterDepartment
                                        valid_indices = []
                                        valid_labels = []
                                        
                                        for idx, dept_label in enumerate(all_departments):
                                            if dept_label.startswith(current_masterdept):
                                                valid_indices.append(idx)
                                                valid_labels.append(dept_label)
                                        
                                        if len(valid_indices) == 0:
                                            self.logger.warning(f"âš ï¸  No Departments found for MasterDepartment: {current_masterdept}")
                                            continue
                                        
                                        # Get probabilities only for valid indices
                                        valid_probs = dept_probs[0][valid_indices]
                                        
                                        # Find the highest probability among valid options
                                        best_valid_idx = torch.argmax(valid_probs).item()
                                        dept_idx = valid_indices[best_valid_idx]
                                        department_label = valid_labels[best_valid_idx]
                                        final_score = valid_probs[best_valid_idx].item()
                                        
                                        # Log the constraint application
                                        original_prediction_idx = torch.argmax(dept_probs, dim=1).item()
                                        original_prediction = all_departments[original_prediction_idx]
                                        
                                        if original_prediction_idx != dept_idx:
                                            self.logger.warning(f"âš ï¸  Hierarchical constraint applied at Level 2!")
                                            self.logger.warning(f"   MasterDepartment: {current_masterdept}")
                                            self.logger.warning(f"   Original: {original_prediction} ({dept_probs[0][original_prediction_idx].item():.3f})")
                                            self.logger.warning(f"   Corrected: {department_label} ({final_score:.3f})")
                                        else:
                                            self.logger.info(f"   âœ“ Level 2: {department_label} ({final_score:.3f})")

                                        predictions.append({
                                            "from_name": from_name_department,
                                            "to_name": to_name_department,
                                            "type": "taxonomy",
                                            "value": {
                                                "taxonomy": [department_label.split(" > ")],
                                                "score": float(final_score)
                                            }
                                        })
                                        
                                        self.logger.info(f"   âœ“ Level 2 prediction: {department_label}")

                                        # ========== LEVEL 3: QUERY TYPE ==========
                                        if self.querytype_model is not None:
                                            try:
                                                conditional_text_qt = (
                                                    f"MasterDepartment: {decoded_masterdept_preds[i]} "
                                                    f"Department: {department_label} "
                                                    f"Email: {current_text}"
                                                )

                                                qt_ids = tokenizer.encode(
                                                    conditional_text_qt,
                                                    add_special_tokens=True,
                                                    max_length=256,
                                                    truncation=True
                                                )
                                                qt_mask = [int(t > 0) for t in qt_ids]

                                                qt_logits = self.querytype_model(
                                                    torch.tensor([qt_ids]).to(device),
                                                    torch.tensor([qt_mask]).to(device)
                                                )

                                                if isinstance(qt_logits, (tuple, list)):
                                                    qt_logits = qt_logits[0]

                                                qt_probs = torch.softmax(qt_logits, dim=1)
                                                
                                                # ========== HIERARCHICAL CONSTRAINT ==========
                                                qt_encoder = self.querytype_model.get_encoder()
                                                all_querytypes = qt_encoder.classes_
                                                
                                                # Filter to only QueryTypes that start with current department
                                                valid_indices = []
                                                valid_labels = []
                                                
                                                for idx, qt_label in enumerate(all_querytypes):
                                                    if qt_label.startswith(department_label):
                                                        valid_indices.append(idx)
                                                        valid_labels.append(qt_label)
                                                
                                                if len(valid_indices) == 0:
                                                    self.logger.warning(f"âš ï¸  No QueryTypes found for department: {department_label}")
                                                    continue
                                                
                                                # Get probabilities only for valid indices
                                                valid_probs = qt_probs[0][valid_indices]
                                                
                                                # Find the highest probability among valid options
                                                best_valid_idx = torch.argmax(valid_probs).item()
                                                qt_idx = valid_indices[best_valid_idx]
                                                querytype_label = valid_labels[best_valid_idx]
                                                final_score = valid_probs[best_valid_idx].item()
                                                
                                                # Log the constraint application
                                                original_prediction_idx = torch.argmax(qt_probs, dim=1).item()
                                                original_prediction = all_querytypes[original_prediction_idx]
                                                
                                                if original_prediction_idx != qt_idx:
                                                    self.logger.warning(f"âš ï¸  Hierarchical constraint applied!")
                                                    self.logger.warning(f"   Original: {original_prediction} ({qt_probs[0][original_prediction_idx].item():.3f})")
                                                    self.logger.warning(f"   Corrected: {querytype_label} ({final_score:.3f})")
                                                else:
                                                    self.logger.info(f"   âœ“ Level 3: {querytype_label} ({final_score:.3f})")

                                                predictions.append({
                                                    "from_name": from_name_querytype,
                                                    "to_name": to_name_querytype,
                                                    "type": "taxonomy",
                                                    "value": {
                                                        "taxonomy": [querytype_label.split(" > ")],
                                                        "score": float(final_score)
                                                    }
                                                })
                                                
                                            except Exception as e:
                                                self.logger.error(f"âŒ Error in Level 3 prediction for item {i}: {e}")
                                                self.logger.exception("Full traceback:")
                                                # Continue without Level 3 prediction
                                                
                                    except Exception as e:
                                        self.logger.error(f"âŒ Error in Level 2 prediction for item {i}: {e}")
                                        self.logger.exception("Full traceback:")
                                        # Continue without Level 2 and Level 3 predictions
                                        
                            except Exception as e:
                                self.logger.error(f"âŒ Error processing item {i} in batch: {e}")
                                self.logger.exception("Full traceback:")
                                # Continue to next item

                self.logger.info("=" * 80)
                self.logger.info(f"âœ… INFERENCE COMPLETE - Generated {len(predictions)} predictions")
                self.logger.info("=" * 80)
                
                return predictions
                
            except Exception as e:
                self.logger.error(f"âŒ Error during inference loop: {e}")
                self.logger.exception("Full traceback:")
                return []
            
        except Exception as e:
            # Catch-all for any unexpected errors
            self.logger.error("=" * 80)
            self.logger.error("âŒ CRITICAL ERROR IN PREDICT METHOD")
            self.logger.error("=" * 80)
            self.logger.error(f"Error: {e}")
            self.logger.exception("Full traceback:")
            
            # Return empty list instead of crashing
            return []