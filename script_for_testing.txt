import streamlit as st
import requests
import pandas as pd
from tqdm import tqdm

from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# =========================
# CONFIG
# =========================
AUTH_URL = "http://10.176.3.178:5080/api/Auth/token"
PREDICT_URL_BERT = "http://10.176.3.178:5080/api/External/Bert-Multi-Task-Classifier/predict"

CSV_PATH = "emails.csv"   # <-- change if needed

EMAIL_COL = "email"                      # column with email text
TRUE_COL = "classification_true"         # ground truth column
PRED_COL = "classification_pred"         # prediction column (will be filled)
CONF_COL = "confidence_score"            # confidence column (new)

# =========================
# AUTH
# =========================
def get_token():
    credentials = {
        "clientId": "client1_id",
        "clientSecret": "client1_secret"
    }
    headers = {"Content-Type": "application/json"}
    resp = requests.post(AUTH_URL, headers=headers, json=credentials)
    resp.raise_for_status()
    return resp.json().get("token")


# =========================
# PAYLOAD BUILDER
# =========================
def build_payload(text):
    return {
        "texts": [
            {
                "id": "1",
                "text": text
            }
        ]
    }


# =========================
# LOAD CSV
# =========================
df = pd.read_csv(CSV_PATH)

if PRED_COL not in df.columns:
    df[PRED_COL] = ""

if CONF_COL not in df.columns:
    df[CONF_COL] = ""

print(f"Loaded {len(df)} rows")


# =========================
# GET TOKEN
# =========================
print("Getting auth token...")
token = get_token()

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {token}"
}


# =========================
# BATCH PREDICTION LOOP
# =========================
for idx, row in tqdm(df.iterrows(), total=len(df)):

    text = str(row[EMAIL_COL])

    if not text.strip():
        continue

    payload = build_payload(text)

    try:
        response = requests.post(
            PREDICT_URL_BERT,
            headers=headers,
            json=payload,
            timeout=60
        )
        response.raise_for_status()

        result = response.json()

        # -------- PARSE YOUR JSON FORMAT --------
        api_block = result["results"][0]["result"]

        classification_pred = ""
        confidence_score = ""

        for item in api_block:
            if item["from_name"] == "classification":
                taxonomy_path = item["value"]["taxonomy"][0]
                classification_pred = " > ".join(taxonomy_path)
                confidence_score = item["value"]["score"]
                break

        df.at[idx, PRED_COL] = classification_pred
        df.at[idx, CONF_COL] = confidence_score

    except Exception as e:
        print(f"Row {idx} failed: {e}")
        df.at[idx, PRED_COL] = "ERROR"
        df.at[idx, CONF_COL] = ""


# =========================
# SAVE PREDICTIONS
# =========================
OUT_PATH = "emails_with_predictions.csv"
df.to_csv(OUT_PATH, index=False)
print(f"Saved predictions → {OUT_PATH}")


# =========================
# EVALUATION METRICS
# =========================
print("\nRunning evaluation...")

eval_df = df[df[PRED_COL] != "ERROR"].copy()

y_true = eval_df[TRUE_COL]
y_pred = eval_df[PRED_COL]

acc = accuracy_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred, average="weighted")

print("\n===== METRICS =====")
print("Accuracy:", acc)
print("F1 weighted:", f1)

report = classification_report(y_true, y_pred)
print("\n===== CLASSIFICATION REPORT =====")
print(report)


# =========================
# CONFUSION MATRIX
# =========================
cm = confusion_matrix(y_true, y_pred)

print("\n===== CONFUSION MATRIX =====")
print(cm)

plt.figure(figsize=(10, 8))
plt.imshow(cm)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.colorbar()
plt.tight_layout()
plt.show()


# =========================
# SAVE METRICS FILE
# =========================
with open("metrics.txt", "w", encoding="utf-8") as f:
    f.write("Accuracy: " + str(acc) + "\n")
    f.write("F1 weighted: " + str(f1) + "\n\n")
    f.write(report)

print("Saved metrics → metrics.txt")
